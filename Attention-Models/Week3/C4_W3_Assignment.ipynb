\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{C4\_W3\_Assignment}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{assignment-3-question-answering}{%
\section{Assignment 3: Question
Answering}\label{assignment-3-question-answering}}

Welcome to this week's assignment of course 4. In this you will explore
question answering. You will implement the ``Text to Text Transfer from
Transformers'' (better known as T5). Since you implemented transformers
from scratch last week you will now be able to use them.

    \hypertarget{outline}{%
\subsection{Outline}\label{outline}}

\begin{itemize}
\tightlist
\item
  Section \ref{0}
\item
  Section \ref{0}
\item
  Section \ref{1}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{11}
  \item
    Section \ref{12}

    \begin{itemize}
    \tightlist
    \item
      Section \ref{121}
    \end{itemize}
  \item
    Section \ref{13}

    \begin{itemize}
    \tightlist
    \item
      Section \ref{ex01}
    \end{itemize}
  \item
    Section \ref{14}
  \end{itemize}
\item
  Section \ref{2}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{21}

    \begin{itemize}
    \tightlist
    \item
      Section \ref{211}

      \begin{itemize}
      \tightlist
      \item
        Section \ref{ex02}
      \end{itemize}
    \item
      Section \ref{212}

      \begin{itemize}
      \tightlist
      \item
        Section \ref{ex03}
      \end{itemize}
    \item
      Section \ref{213}

      \begin{itemize}
      \tightlist
      \item
        Section \ref{ex04}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{itemize}

    \#\#\# Overview

This assignment will be different from the two previous ones. Due to
memory and time constraints of this environment you will not be able to
train a model and use it for inference. Instead you will create the
necessary building blocks for the transformer encoder model and will use
a pretrained version of the same model in two ungraded labs after this
assignment.

After completing these 3 (1 graded and 2 ungraded) labs you will: *
Implement the code neccesary for Bidirectional Encoder Representation
from Transformer (BERT). * Understand how the C4 dataset is structured.
* Use a pretrained model for inference. * Understand how the ``Text to
Text Transfer from Transformers'' or T5 model works.

    \# Part 0: Importing the Packages

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{ast}
\PY{k+kn}{import} \PY{n+nn}{string}
\PY{k+kn}{import} \PY{n+nn}{textwrap}
\PY{k+kn}{import} \PY{n+nn}{itertools}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}

\PY{k+kn}{import} \PY{n+nn}{trax} 
\PY{k+kn}{from} \PY{n+nn}{trax} \PY{k+kn}{import} \PY{n}{layers} \PY{k}{as} \PY{n}{tl}
\PY{k+kn}{from} \PY{n+nn}{trax}\PY{n+nn}{.}\PY{n+nn}{supervised} \PY{k+kn}{import} \PY{n}{decoding}

\PY{c+c1}{\PYZsh{} Will come handy later.}
\PY{n}{wrapper} \PY{o}{=} \PY{n}{textwrap}\PY{o}{.}\PY{n}{TextWrapper}\PY{p}{(}\PY{n}{width}\PY{o}{=}\PY{l+m+mi}{70}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Set random seed}
\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:tokens\_length=568 inputs\_length=512 targets\_length=114
noise\_density=0.15 mean\_noise\_span\_length=3.0
    \end{Verbatim}

    \#\# Part 1: C4 Dataset

The \href{https://www.tensorflow.org/datasets/catalog/c4}{C4} is a huge
data set. For the purpose of this assignment you will use a few examples
out of it which are present in \texttt{data.txt}. C4 is based on the
\href{https://commoncrawl.org/}{common crawl} project. Feel free to read
more on their website.

Run the cell below to see how the examples look like.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} load example jsons}
\PY{n}{example\PYZus{}jsons} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{ast}\PY{o}{.}\PY{n}{literal\PYZus{}eval}\PY{p}{,} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Printing the examples to see how the data looks like}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{example number }\PY{l+s+si}{\PYZob{}}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{example\PYZus{}jsons}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
example number 1:

\{'content-length': b'1970', 'content-type': b'text/plain', 'text': b'Beginners
BBQ Class Taking Place in Missoula!\textbackslash{}nDo you want to get better at making
delicious BBQ? You will have the opportunity, put this on your calendar now.
Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar
Smoke Rangers. He will be teaching a beginner level class for everyone who wants
to get better with their culinary skills.\textbackslash{}nHe will teach you everything you need
to know to compete in a KCBS BBQ competition, including techniques, recipes,
timelines, meat selection and trimming, plus smoker and fire information.\textbackslash{}nThe
cost to be in the class is \$35 per person, and for spectators it is free.
Included in the cost will be either a t-shirt or apron and you will be tasting
samples of each meat that is prepared.', 'timestamp': b'2019-04-25T12:57:54Z',
'url': b'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'\}

example number 2:

\{'content-length': b'12064', 'content-type': b'text/plain', 'text': b'Discussion
in \textbackslash{}'Mac OS X Lion (10.7)\textbackslash{}' started by axboi87, Jan 20, 2012.\textbackslash{}nI\textbackslash{}'ve got a 500gb
internal drive and a 240gb SSD.\textbackslash{}nWhen trying to restore using disk utility i\textbackslash{}'m
given the error "Not enough space on disk \_\_\_\_ to restore"\textbackslash{}nBut I shouldn\textbackslash{}'t
have to do that!!!\textbackslash{}nAny ideas or workarounds before resorting to the above?\textbackslash{}nUse
Carbon Copy Cloner to copy one drive to the other. I\textbackslash{}'ve done this several times
going from larger HDD to smaller SSD and I wound up with a bootable SSD drive.
One step you have to remember not to skip is to use Disk Utility to partition
the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple
Partition Scheme, even if you let CCC do the clone, the resulting drive won\textbackslash{}'t
be bootable. CCC usually works in "file mode" and it can easily copy a larger
drive (that\textbackslash{}'s mostly empty) onto a smaller drive. If you tell CCC to clone a
drive you did NOT boot from, it can work in block copy mode where the
destination drive must be the same size or larger than the drive you are cloning
from (if I recall).\textbackslash{}nI\textbackslash{}'ve actually done this somehow on Disk Utility several
times (booting from a different drive (or even the dvd) so not running disk
utility from the drive your cloning) and had it work just fine from larger to
smaller bootable clone. Definitely format the drive cloning to first, as
bootable Apple etc..\textbackslash{}nThanks for pointing this out. My only experience using DU
to go larger to smaller was when I was trying to make a Lion install stick and I
was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the
reason that wouldn\textbackslash{}'t fit is there was slightly more than 4 GB of data.',
'timestamp': b'2019-04-21T10:07:13Z', 'url':
b'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-
disk.1311329/'\}

example number 3:

\{'content-length': b'5235', 'content-type': b'text/plain', 'text': b'Foil plaid
lycra and spandex shortall with metallic slinky insets. Attached metallic
elastic belt with O-ring. Headband included. Great hip hop or jazz dance
costume. Made in the USA.', 'timestamp': b'2019-04-25T10:40:23Z', 'url':
b'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'\}

example number 4:

\{'content-length': b'4967', 'content-type': b'text/plain', 'text': b"How many
backlinks per day for new site?\textbackslash{}nDiscussion in 'Black Hat SEO' started by
Omoplata, Dec 3, 2010.\textbackslash{}n1) for a newly created site, what's the max \# backlinks
per day I should do to be safe?\textbackslash{}n2) how long do I have to let my site age before
I can start making more blinks?\textbackslash{}nI did about 6000 forum profiles every 24 hours
for 10 days for one of my sites which had a brand new domain.\textbackslash{}nThere is three
backlinks for every of these forum profile so thats 18 000 backlinks every 24
hours and nothing happened in terms of being penalized or sandboxed. This is now
maybe 3 months ago and the site is ranking on first page for a lot of my
targeted keywords.\textbackslash{}nbuild more you can in starting but do manual submission and
not spammy type means manual + relevant to the post.. then after 1 month you can
make a big blast..\textbackslash{}nWow, dude, you built 18k backlinks a day on a brand new
site? How quickly did you rank up? What kind of competition/searches did those
keywords have?", 'timestamp': b'2019-04-21T12:46:19Z', 'url':
b'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-
site.258615/'\}

example number 5:

\{'content-length': b'4499', 'content-type': b'text/plain', 'text': b'The Denver
Board of Education opened the 2017-18 school year with an update on projects
that include new construction, upgrades, heat mitigation and quality learning
environments.\textbackslash{}nWe are excited that Denver students will be the beneficiaries of
a four year, \$572 million General Obligation Bond. Since the passage of the
bond, our construction team has worked to schedule the projects over the four-
year term of the bond.\textbackslash{}nDenver voters on Tuesday approved bond and mill funding
measures for students in Denver Public Schools, agreeing to invest \$572 million
in bond funding to build and improve schools and \$56.6 million in operating
dollars to support proven initiatives, such as early literacy.\textbackslash{}nDenver voters
say yes to bond and mill levy funding support for DPS students and schools.
Click to learn more about the details of the voter-approved bond
measure.\textbackslash{}nDenver voters on Nov. 8 approved bond and mill funding measures for
DPS students and schools. Learn more about what\textbackslash{}xe2\textbackslash{}x80\textbackslash{}x99s included in the
mill levy measure.', 'timestamp': b'2019-04-20T14:33:21Z', 'url':
b'http://bond.dpsk12.org/category/news/'\}

    \end{Verbatim}

    Notice the \texttt{b} before each string? This means that this data
comes as bytes rather than strings. Strings are actually lists of bytes
so for the rest of the assignments the name \texttt{strings} will be
used to describe the data.

To check this run the following cell:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{type}\PY{p}{(}\PY{n}{example\PYZus{}jsons}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
bytes
\end{Verbatim}
\end{tcolorbox}
        
    \#\#\# 1.1 Pre-Training Objective

\textbf{Note:} The word ``mask'' will be used throughout this assignment
in context of hiding/removing word(s)

You will be implementing the BERT loss as shown in the following image.

Assume you have the following text: { \textbf{Thank you {for inviting }
me to your party {last} week} }

Now as input you will mask the words in red in the text:

{ \textbf{Input:}} Thank you \textbf{X} me to your party \textbf{Y}
week.

{\textbf{Output:}} The model should predict the words(s) for \textbf{X}
and \textbf{Y}.

\textbf{Z} is used to represent the end.

    \#\#\# 1.2 Process C4

C4 only has the plain string \texttt{text} field, so you will tokenize
and have \texttt{inputs} and \texttt{targets} out of it for supervised
learning. Given your inputs, the goal is to predict the targets during
training.

You will now take the \texttt{text} and convert it to \texttt{inputs}
and \texttt{targets}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Grab text field from dictionary}
\PY{n}{natural\PYZus{}language\PYZus{}texts} \PY{o}{=} \PY{p}{[}\PY{n}{example\PYZus{}json}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{example\PYZus{}json} \PY{o+ow}{in} \PY{n}{example\PYZus{}jsons}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} First text example}
\PY{n}{natural\PYZus{}language\PYZus{}texts}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
b'The Denver Board of Education opened the 2017-18 school year with an update on
projects that include new construction, upgrades, heat mitigation and quality
learning environments.\textbackslash{}nWe are excited that Denver students will be the
beneficiaries of a four year, \$572 million General Obligation Bond. Since the
passage of the bond, our construction team has worked to schedule the projects
over the four-year term of the bond.\textbackslash{}nDenver voters on Tuesday approved bond and
mill funding measures for students in Denver Public Schools, agreeing to invest
\$572 million in bond funding to build and improve schools and \$56.6 million in
operating dollars to support proven initiatives, such as early literacy.\textbackslash{}nDenver
voters say yes to bond and mill levy funding support for DPS students and
schools. Click to learn more about the details of the voter-approved bond
measure.\textbackslash{}nDenver voters on Nov. 8 approved bond and mill funding measures for
DPS students and schools. Learn more about what\textbackslash{}xe2\textbackslash{}x80\textbackslash{}x99s included in the
mill levy measure.'
\end{Verbatim}
\end{tcolorbox}
        
    \#\#\#\# 1.2.1 Decode to natural language

The following functions will help you \texttt{detokenize}
and\texttt{tokenize} the text data.

The \texttt{sentencepiece} vocabulary was used to convert from text to
ids. This vocabulary file is loaded and used in this helper functions.

\texttt{natural\_language\_texts} has the text from the examples we gave
you.

Run the cells below to see what is going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Special tokens}
\PY{n}{PAD}\PY{p}{,} \PY{n}{EOS}\PY{p}{,} \PY{n}{UNK} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}

\PY{k}{def} \PY{n+nf}{detokenize}\PY{p}{(}\PY{n}{np\PYZus{}array}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{detokenize}\PY{p}{(}
        \PY{n}{np\PYZus{}array}\PY{p}{,}
        \PY{n}{vocab\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece.model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{tokenize}\PY{p}{(}\PY{n}{s}\PY{p}{)}\PY{p}{:}
  \PY{c+c1}{\PYZsh{} The trax.data.tokenize function operates on streams,}
  \PY{c+c1}{\PYZsh{} that\PYZsq{}s why we have to create 1\PYZhy{}element stream with iter}
  \PY{c+c1}{\PYZsh{} and later retrieve the result with next.}
    \PY{k}{return} \PY{n+nb}{next}\PY{p}{(}\PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{tokenize}\PY{p}{(}
        \PY{n+nb}{iter}\PY{p}{(}\PY{p}{[}\PY{n}{s}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{n}{vocab\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece.model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} printing the encoding of each word to see how subwords are tokenized}
\PY{n}{tokenized\PYZus{}text} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{n}{tokenize}\PY{p}{(}\PY{n}{word}\PY{p}{)}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{word}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{natural\PYZus{}language\PYZus{}texts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{tokenized\PYZus{}text}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[([12847, 277], b'Beginners'), ([15068], b'BBQ'), ([4501], b'Class'), ([3,
12297], b'Taking'), ([3399], b'Place'), ([16], b'in'), ([5964, 7115, 9, 55],
b'Missoula!'), ([531], b'Do'), ([25], b'you'), ([241], b'want'), ([12], b'to'),
([129], b'get'), ([394], b'better'), ([44], b'at'), ([492], b'making'), ([3326],
b'delicious'), ([15068, 58], b'BBQ?'), ([148], b'You'), ([56], b'will'), ([43],
b'have'), ([8], b'the'), ([1004, 6], b'opportunity,'), ([474], b'put'), ([48],
b'this'), ([30], b'on'), ([39], b'your'), ([4793], b'calendar'), ([230, 5],
b'now.'), ([2721, 6], b'Thursday,'), ([1600], b'September'), ([1630, 727],
b'22nd'), ([1715], b'join'), ([1150], b'World'), ([4501], b'Class'), ([15068],
b'BBQ'), ([16127, 6], b'Champion,'), ([9137], b'Tony'), ([2659, 5595],
b'Balay'), ([45], b'from'), ([301, 782, 3624], b'Lonestar'), ([14627, 15],
b'Smoke'), ([12612, 277, 5], b'Rangers.'), ([216], b'He'), ([56], b'will'),
([36], b'be'), ([2119], b'teaching'), ([3, 9], b'a'), ([19529], b'beginner'),
([593], b'level'), ([853], b'class'), ([21], b'for'), ([921], b'everyone'),
([113], b'who'), ([2746], b'wants'), ([12], b'to'), ([129], b'get'), ([394],
b'better'), ([28], b'with'), ([70], b'their'), ([17712], b'culinary'), ([1098,
5], b'skills.'), ([216], b'He'), ([56], b'will'), ([3884], b'teach'), ([25],
b'you'), ([762], b'everything'), ([25], b'you'), ([174], b'need'), ([12],
b'to'), ([214], b'know'), ([12], b'to'), ([5978], b'compete'), ([16], b'in'),
([3, 9], b'a'), ([3, 23405, 4547], b'KCBS'), ([15068], b'BBQ'), ([2259, 6],
b'competition,'), ([379], b'including'), ([2097, 6], b'techniques,'), ([5459,
6], b'recipes,'), ([13618, 7, 6], b'timelines,'), ([3604], b'meat'), ([1801],
b'selection'), ([11], b'and'), ([27856, 6], b'trimming,'), ([303], b'plus'),
([24190], b'smoker'), ([11], b'and'), ([1472], b'fire'), ([251, 5],
b'information.'), ([37], b'The'), ([583], b'cost'), ([12], b'to'), ([36],
b'be'), ([16], b'in'), ([8], b'the'), ([853], b'class'), ([19], b'is'),
([25264], b'\$35'), ([399], b'per'), ([568, 6], b'person,'), ([11], b'and'),
([21], b'for'), ([21380, 7], b'spectators'), ([34], b'it'), ([19], b'is'),
([339, 5], b'free.'), ([15746, 26], b'Included'), ([16], b'in'), ([8], b'the'),
([583], b'cost'), ([56], b'will'), ([36], b'be'), ([893], b'either'), ([3, 9],
b'a'), ([3, 17, 18, 9486], b't-shirt'), ([42], b'or'), ([3, 9, 1409, 29],
b'apron'), ([11], b'and'), ([25], b'you'), ([56], b'will'), ([36], b'be'),
([12246], b'tasting'), ([5977], b'samples'), ([13], b'of'), ([284], b'each'),
([3604], b'meat'), ([24], b'that'), ([19], b'is'), ([2657, 5], b'prepared.')]

    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We can see that detokenize successfully undoes the tokenization}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{tokenized: }\PY{l+s+si}{\PYZob{}}\PY{n}{tokenize}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Beginners}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{detokenized: }\PY{l+s+si}{\PYZob{}}\PY{n}{detokenize}\PY{p}{(}\PY{n}{tokenize}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Beginners}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
tokenized: [12847   277]
detokenized: Beginners
    \end{Verbatim}

    As you can see above, you were able to take a piece of string and
tokenize it.

Now you will create \texttt{input} and \texttt{target} pairs that will
allow you to train your model. T5 uses the ids at the end of the vocab
file as sentinels. For example, it will replace: -
\texttt{vocab\_size\ -\ 1} by \texttt{\textless{}Z\textgreater{}} -
\texttt{vocab\_size\ -\ 2} by \texttt{\textless{}Y\textgreater{}} - and
so forth.

It assigns every word a \texttt{chr}.

The \texttt{pretty\_decode} function below, which you will use in a bit,
helps in handling the type when decoding. Take a look and try to
understand what the function is doing.

Notice that:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{string.ascii\_letters }\OperatorTok{=} \StringTok{\textquotesingle{}abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

\textbf{NOTE:} Targets may have more than the 52 sentinels we replace,
but this is just to give you an idea of things.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{vocab\PYZus{}size} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{vocab\PYZus{}size}\PY{p}{(}
    \PY{n}{vocab\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentencepiece.model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{get\PYZus{}sentinels}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{n}{vocab\PYZus{}size}\PY{p}{,} \PY{n}{display}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{n}{sentinels} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{char} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{reversed}\PY{p}{(}\PY{n}{string}\PY{o}{.}\PY{n}{ascii\PYZus{}letters}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        \PY{n}{decoded\PYZus{}text} \PY{o}{=} \PY{n}{detokenize}\PY{p}{(}\PY{p}{[}\PY{n}{vocab\PYZus{}size} \PY{o}{\PYZhy{}} \PY{n}{i}\PY{p}{]}\PY{p}{)} 
        
        \PY{c+c1}{\PYZsh{} Sentinels, ex: \PYZlt{}Z\PYZgt{} \PYZhy{} \PYZlt{}a\PYZgt{}}
        \PY{n}{sentinels}\PY{p}{[}\PY{n}{decoded\PYZus{}text}\PY{p}{]} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}}\PY{l+s+si}{\PYZob{}}\PY{n}{char}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}    
    
        \PY{k}{if} \PY{n}{display}\PY{p}{:}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The sentinel is \PYZlt{}}\PY{l+s+si}{\PYZob{}}\PY{n}{char}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZgt{} and the decoded token is:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{decoded\PYZus{}text}\PY{p}{)}

    \PY{k}{return} \PY{n}{sentinels}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sentinels} \PY{o}{=} \PY{n}{get\PYZus{}sentinels}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{p}{,} \PY{n}{display}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
The sentinel is <Z> and the decoded token is: Internațional
The sentinel is <Y> and the decoded token is: erwachsene
The sentinel is <X> and the decoded token is: Cushion
The sentinel is <W> and the decoded token is: imunitar
The sentinel is <V> and the decoded token is: Intellectual
The sentinel is <U> and the decoded token is: traditi
The sentinel is <T> and the decoded token is: disguise
The sentinel is <S> and the decoded token is: exerce
The sentinel is <R> and the decoded token is: nourishe
The sentinel is <Q> and the decoded token is: predominant
The sentinel is <P> and the decoded token is: amitié
The sentinel is <O> and the decoded token is: erkennt
The sentinel is <N> and the decoded token is: dimension
The sentinel is <M> and the decoded token is: inférieur
The sentinel is <L> and the decoded token is: refugi
The sentinel is <K> and the decoded token is: cheddar
The sentinel is <J> and the decoded token is: unterlieg
The sentinel is <I> and the decoded token is: garanteaz
The sentinel is <H> and the decoded token is: făcute
The sentinel is <G> and the decoded token is: réglage
The sentinel is <F> and the decoded token is: pedepse
The sentinel is <E> and the decoded token is: Germain
The sentinel is <D> and the decoded token is: distinctly
The sentinel is <C> and the decoded token is: Schraub
The sentinel is <B> and the decoded token is: emanat
The sentinel is <A> and the decoded token is: trimestre
The sentinel is <z> and the decoded token is: disrespect
The sentinel is <y> and the decoded token is: Erasmus
The sentinel is <x> and the decoded token is: Australia
The sentinel is <w> and the decoded token is: permeabil
The sentinel is <v> and the decoded token is: deseori
The sentinel is <u> and the decoded token is: manipulated
The sentinel is <t> and the decoded token is: suggér
The sentinel is <s> and the decoded token is: corespund
The sentinel is <r> and the decoded token is: nitro
The sentinel is <q> and the decoded token is: oyons
The sentinel is <p> and the decoded token is: Account
The sentinel is <o> and the decoded token is: échéan
The sentinel is <n> and the decoded token is: laundering
The sentinel is <m> and the decoded token is: genealogy
The sentinel is <l> and the decoded token is: QuickBooks
The sentinel is <k> and the decoded token is: constituted
The sentinel is <j> and the decoded token is: Fertigung
The sentinel is <i> and the decoded token is: goutte
The sentinel is <h> and the decoded token is: regulă
The sentinel is <g> and the decoded token is: overwhelmingly
The sentinel is <f> and the decoded token is: émerg
The sentinel is <e> and the decoded token is: broyeur
The sentinel is <d> and the decoded token is: povești
The sentinel is <c> and the decoded token is: emulator
The sentinel is <b> and the decoded token is: halloween
The sentinel is <a> and the decoded token is: combustibil
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{encoded\PYZus{}str\PYZus{}list}\PY{p}{,} \PY{n}{sentinels}\PY{o}{=}\PY{n}{sentinels}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} If already a string, just do the replacements.}
    \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{encoded\PYZus{}str\PYZus{}list}\PY{p}{,} \PY{p}{(}\PY{n+nb}{str}\PY{p}{,} \PY{n+nb}{bytes}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{token}\PY{p}{,} \PY{n}{char} \PY{o+ow}{in} \PY{n}{sentinels}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{n}{encoded\PYZus{}str\PYZus{}list} \PY{o}{=} \PY{n}{encoded\PYZus{}str\PYZus{}list}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{token}\PY{p}{,} \PY{n}{char}\PY{p}{)}
        \PY{k}{return} \PY{n}{encoded\PYZus{}str\PYZus{}list}
  
    \PY{c+c1}{\PYZsh{} We need to decode and then prettyfy it.}
    \PY{k}{return} \PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{detokenize}\PY{p}{(}\PY{n}{encoded\PYZus{}str\PYZus{}list}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I want to dress up as an Intellectual this halloween.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
'I want to dress up as an <V> this <b>.'
\end{Verbatim}
\end{tcolorbox}
        
    The functions above make your \texttt{inputs} and \texttt{targets} more
readable. For example, you might see something like this once you
implement the masking function below.

\begin{itemize}
\tightlist
\item
  { Input sentence: } Younes and Lukasz were working together in the lab
  yesterday after lunch.
\item
  {Input: } Younes and Lukasz \textbf{Z} together in the \textbf{Y}
  yesterday after lunch.
\item
  {Target: } \textbf{Z} were working \textbf{Y} lab.
\end{itemize}

    \#\#\# 1.3 Tokenizing and Masking

You will now implement the \texttt{tokenize\_and\_mask} function. This
function will allow you to tokenize and mask input words with a noise
probability. We usually mask 15\% of the words.

    \#\#\# Exercise 01

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C1}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: tokenize\PYZus{}and\PYZus{}mask}
\PY{k}{def} \PY{n+nf}{tokenize\PYZus{}and\PYZus{}mask}\PY{p}{(}\PY{n}{text}\PY{p}{,} \PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{n}{vocab\PYZus{}size}\PY{p}{,} \PY{n}{noise}\PY{o}{=}\PY{l+m+mf}{0.15}\PY{p}{,} 
                      \PY{n}{randomizer}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{,} \PY{n}{tokenize}\PY{o}{=}\PY{n}{tokenize}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Tokenizes and masks a given input.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        text (str or bytes): Text input.}
\PY{l+s+sd}{        vocab\PYZus{}size (int, optional): Size of the vocabulary. Defaults to vocab\PYZus{}size.}
\PY{l+s+sd}{        noise (float, optional): Probability of masking a token. Defaults to 0.15.}
\PY{l+s+sd}{        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.}
\PY{l+s+sd}{        tokenize (function, optional): Tokenizer function. Defaults to tokenize.}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        tuple: Tuple of lists of integers associated to inputs and targets.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{c+c1}{\PYZsh{} current sentinel number (starts at 0)}
    \PY{n}{cur\PYZus{}sentinel\PYZus{}num} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{c+c1}{\PYZsh{} inputs}
    \PY{n}{inps} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{c+c1}{\PYZsh{} targets}
    \PY{n}{targs} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} prev\PYZus{}no\PYZus{}mask is True if the previous token was NOT masked, False otherwise}
    \PY{c+c1}{\PYZsh{} set prev\PYZus{}no\PYZus{}mask to True}
    \PY{n}{prev\PYZus{}no\PYZus{}mask} \PY{o}{=} \PY{k+kc}{True}
    
    \PY{c+c1}{\PYZsh{} loop through tokenized `text`}
    \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
        \PY{c+c1}{\PYZsh{} check if the `noise` is greater than a random value (weighted coin flip)}
        \PY{k}{if} \PY{n}{randomizer}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZlt{}} \PY{n}{noise}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} check to see if the previous token was not masked}
            \PY{k}{if} \PY{n}{prev\PYZus{}no\PYZus{}mask}\PY{o}{==}\PY{k+kc}{True}\PY{p}{:} \PY{c+c1}{\PYZsh{} add new masked token at end\PYZus{}id}
                \PY{c+c1}{\PYZsh{} number of masked tokens increases by 1}
                \PY{n}{cur\PYZus{}sentinel\PYZus{}num} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                \PY{c+c1}{\PYZsh{} compute `end\PYZus{}id` by subtracting current sentinel value out of the total vocabulary size}
                \PY{n}{end\PYZus{}id} \PY{o}{=} \PY{n}{vocab\PYZus{}size} \PY{o}{\PYZhy{}} \PY{n}{cur\PYZus{}sentinel\PYZus{}num}
                \PY{c+c1}{\PYZsh{} append `end\PYZus{}id` at the end of the targets}
                \PY{n}{targs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{end\PYZus{}id}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} append `end\PYZus{}id` at the end of the inputs}
                \PY{n}{inps}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{end\PYZus{}id}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} append `token` at the end of the targets}
            \PY{n}{targs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} set prev\PYZus{}no\PYZus{}mask accordingly}
            \PY{n}{prev\PYZus{}no\PYZus{}mask} \PY{o}{=} \PY{k+kc}{False}
        
        \PY{k}{else}\PY{p}{:} \PY{c+c1}{\PYZsh{} don\PYZsq{}t have two masked tokens in a row}
            \PY{c+c1}{\PYZsh{} append `token ` at the end of the inputs}
            \PY{n}{inps}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} set prev\PYZus{}no\PYZus{}mask accordingly}
            \PY{n}{prev\PYZus{}no\PYZus{}mask} \PY{o}{=} \PY{k+kc}{True}
            
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{k}{return} \PY{n}{inps}\PY{p}{,} \PY{n}{targs}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Some logic to mock a np.random value generator}
\PY{c+c1}{\PYZsh{} Needs to be in the same cell for it to always generate same output}
\PY{k}{def} \PY{n+nf}{testing\PYZus{}rnd}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf}{dummy\PYZus{}generator}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{vals} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
        \PY{n}{cyclic\PYZus{}vals} \PY{o}{=} \PY{n}{itertools}\PY{o}{.}\PY{n}{cycle}\PY{p}{(}\PY{n}{vals}\PY{p}{)}
        \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{:}
            \PY{k}{yield} \PY{n+nb}{next}\PY{p}{(}\PY{n}{cyclic\PYZus{}vals}\PY{p}{)}

    \PY{n}{dumr} \PY{o}{=} \PY{n}{itertools}\PY{o}{.}\PY{n}{cycle}\PY{p}{(}\PY{n}{dummy\PYZus{}generator}\PY{p}{(}\PY{p}{)}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{dummy\PYZus{}randomizer}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{k}{return} \PY{n+nb}{next}\PY{p}{(}\PY{n}{dumr}\PY{p}{)}
    
    \PY{k}{return} \PY{n}{dummy\PYZus{}randomizer}

\PY{n}{input\PYZus{}str} \PY{o}{=} \PY{n}{natural\PYZus{}language\PYZus{}texts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{input string:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{input\PYZus{}str}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{inps}\PY{p}{,} \PY{n}{targs} \PY{o}{=} \PY{n}{tokenize\PYZus{}and\PYZus{}mask}\PY{p}{(}\PY{n}{input\PYZus{}str}\PY{p}{,} \PY{n}{randomizer}\PY{o}{=}\PY{n}{testing\PYZus{}rnd}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{tokenized inputs:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{inps}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{targets:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{targs}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
input string:

b'Beginners BBQ Class Taking Place in Missoula!\textbackslash{}nDo you want to get better at
making delicious BBQ? You will have the opportunity, put this on your calendar
now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from
Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone
who wants to get better with their culinary skills.\textbackslash{}nHe will teach you
everything you need to know to compete in a KCBS BBQ competition, including
techniques, recipes, timelines, meat selection and trimming, plus smoker and
fire information.\textbackslash{}nThe cost to be in the class is \$35 per person, and for
spectators it is free. Included in the cost will be either a t-shirt or apron
and you will be tasting samples of each meat that is prepared.'

tokenized inputs:

[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12,
129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793,
230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659,
5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5, 216, 31993, 2119, 3, 9, 19529,
593, 853, 21, 921, 31992, 12, 129, 394, 28, 70, 17712, 1098, 5, 31991, 3884, 25,
762, 25, 174, 12, 214, 12, 31990, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 31989,
6, 5459, 6, 13618, 7, 6, 3604, 1801, 31988, 6, 303, 24190, 11, 1472, 251, 5, 37,
31987, 36, 16, 8, 853, 19, 25264, 399, 568, 31986, 21, 21380, 7, 34, 19, 339, 5,
15746, 31985, 8, 583, 56, 36, 893, 3, 9, 3, 31984, 9486, 42, 3, 9, 1409, 29, 11,
25, 31983, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 31982]

targets:

[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727,
1715, 31994, 45, 301, 31993, 56, 36, 31992, 113, 2746, 31991, 216, 56, 31990,
5978, 16, 31989, 379, 2097, 31988, 11, 27856, 31987, 583, 12, 31986, 6, 11,
31985, 26, 16, 31984, 17, 18, 31983, 56, 36, 31982, 5]
    \end{Verbatim}

    \hypertarget{expected-output}{%
\paragraph{\texorpdfstring{\textbf{Expected
Output:}}{Expected Output:}}\label{expected-output}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b}\CharTok{\textquotesingle{}B}\ErrorTok{eginners BBQ Class Taking Place in Missoula!\textbackslash{}nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\textbackslash{}nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\textbackslash{}nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t{-}shirt or apron and you will be tasting samples of each meat that is prepared.}\CharTok{\textquotesingle{}}

\NormalTok{tokenized inputs:}

\NormalTok{[}\DecValTok{31999}\NormalTok{, }\DecValTok{15068}\NormalTok{, }\DecValTok{4501}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{12297}\NormalTok{, }\DecValTok{3399}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{5964}\NormalTok{, }\DecValTok{7115}\NormalTok{, }\DecValTok{31998}\NormalTok{, }\DecValTok{531}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{241}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{129}\NormalTok{, }\DecValTok{394}\NormalTok{, }\DecValTok{44}\NormalTok{, }\DecValTok{492}\NormalTok{, }\DecValTok{31997}\NormalTok{, }\DecValTok{58}\NormalTok{, }\DecValTok{148}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{1004}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{474}\NormalTok{, }\DecValTok{31996}\NormalTok{, }\DecValTok{39}\NormalTok{, }\DecValTok{4793}\NormalTok{, }\DecValTok{230}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2721}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1600}\NormalTok{, }\DecValTok{1630}\NormalTok{, }\DecValTok{31995}\NormalTok{, }\DecValTok{1150}\NormalTok{, }\DecValTok{4501}\NormalTok{, }\DecValTok{15068}\NormalTok{, }\DecValTok{16127}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9137}\NormalTok{, }\DecValTok{2659}\NormalTok{, }\DecValTok{5595}\NormalTok{, }\DecValTok{31994}\NormalTok{, }\DecValTok{782}\NormalTok{, }\DecValTok{3624}\NormalTok{, }\DecValTok{14627}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{12612}\NormalTok{, }\DecValTok{277}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{216}\NormalTok{, }\DecValTok{31993}\NormalTok{, }\DecValTok{2119}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{19529}\NormalTok{, }\DecValTok{593}\NormalTok{, }\DecValTok{853}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{921}\NormalTok{, }\DecValTok{31992}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{129}\NormalTok{, }\DecValTok{394}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{17712}\NormalTok{, }\DecValTok{1098}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{31991}\NormalTok{, }\DecValTok{3884}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{762}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{174}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{214}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{31990}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{23405}\NormalTok{, }\DecValTok{4547}\NormalTok{, }\DecValTok{15068}\NormalTok{, }\DecValTok{2259}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{31989}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5459}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{13618}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3604}\NormalTok{, }\DecValTok{1801}\NormalTok{, }\DecValTok{31988}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{303}\NormalTok{, }\DecValTok{24190}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{1472}\NormalTok{, }\DecValTok{251}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{37}\NormalTok{, }\DecValTok{31987}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{853}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{25264}\NormalTok{, }\DecValTok{399}\NormalTok{, }\DecValTok{568}\NormalTok{, }\DecValTok{31986}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{21380}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{34}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{339}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{15746}\NormalTok{, }\DecValTok{31985}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{583}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{893}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{31984}\NormalTok{, }\DecValTok{9486}\NormalTok{, }\DecValTok{42}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{1409}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{31983}\NormalTok{, }\DecValTok{12246}\NormalTok{, }\DecValTok{5977}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{284}\NormalTok{, }\DecValTok{3604}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{2657}\NormalTok{, }\DecValTok{31982}\NormalTok{]}

\NormalTok{targets:}

\NormalTok{[}\DecValTok{31999}\NormalTok{, }\DecValTok{12847}\NormalTok{, }\DecValTok{277}\NormalTok{, }\DecValTok{31998}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{55}\NormalTok{, }\DecValTok{31997}\NormalTok{, }\DecValTok{3326}\NormalTok{, }\DecValTok{15068}\NormalTok{, }\DecValTok{31996}\NormalTok{, }\DecValTok{48}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{31995}\NormalTok{, }\DecValTok{727}\NormalTok{, }\DecValTok{1715}\NormalTok{, }\DecValTok{31994}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{301}\NormalTok{, }\DecValTok{31993}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{31992}\NormalTok{, }\DecValTok{113}\NormalTok{, }\DecValTok{2746}\NormalTok{, }\DecValTok{31991}\NormalTok{, }\DecValTok{216}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{31990}\NormalTok{, }\DecValTok{5978}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{31989}\NormalTok{, }\DecValTok{379}\NormalTok{, }\DecValTok{2097}\NormalTok{, }\DecValTok{31988}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{27856}\NormalTok{, }\DecValTok{31987}\NormalTok{, }\DecValTok{583}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{31986}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{31985}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{31984}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{31983}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{31982}\NormalTok{, }\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

    You will now use the inputs and the targets from the
\texttt{tokenize\_and\_mask} function you implemented above. Take a look
at the masked sentence using your \texttt{inps} and \texttt{targs} from
the sentence above.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Inputs: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{inps}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Targets: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{targs}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Inputs:

 <Z> BBQ Class Taking Place in Missoul <Y> Do you want to get better at making
<X>? You will have the opportunity, put <W> your calendar now. Thursday,
September 22 <V> World Class BBQ Champion, Tony Balay <U>onestar Smoke Rangers.
He <T> teaching a beginner level class for everyone<S> to get better with their
culinary skills.<R> teach you everything you need to know to <Q> a KCBS BBQ
competition,<P>, recipes, timelines, meat selection <O>, plus smoker and fire
information. The<N> be in the class is \$35 per person <M> for spectators it is
free. Include <L> the cost will be either a  <K>shirt or apron and you <J>
tasting samples of each meat that is prepared <I>

Targets:

 <Z> Beginners <Y>a! <X> delicious BBQ <W> this on <V>nd join <U> from L <T>
will be<S> who wants<R> He will <Q> compete in<P> including techniques <O> and
trimming<N> cost to <M>, and <L>d in <K>t- <J> will be <I>.
    \end{Verbatim}

    \#\#\# 1.4 Creating the Pairs

You will now create pairs using your dataset. You will iterate over your
data and create (inp, targ) pairs using the functions that we have given
you.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Apply tokenize\PYZus{}and\PYZus{}mask}
\PY{n}{inputs\PYZus{}targets\PYZus{}pairs} \PY{o}{=} \PY{p}{[}\PY{n}{tokenize\PYZus{}and\PYZus{}mask}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{text} \PY{o+ow}{in} \PY{n}{natural\PYZus{}language\PYZus{}texts}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{display\PYZus{}input\PYZus{}target\PYZus{}pairs}\PY{p}{(}\PY{n}{inputs\PYZus{}targets\PYZus{}pairs}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{inp\PYZus{}tgt\PYZus{}pair} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{inputs\PYZus{}targets\PYZus{}pairs}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        \PY{n}{inps}\PY{p}{,} \PY{n}{tgts} \PY{o}{=} \PY{n}{inp\PYZus{}tgt\PYZus{}pair}
        \PY{n}{inps}\PY{p}{,} \PY{n}{tgts} \PY{o}{=} \PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{inps}\PY{p}{)}\PY{p}{,} \PY{n}{pretty\PYZus{}decode}\PY{p}{(}\PY{n}{tgts}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[}\PY{l+s+si}{\PYZob{}}\PY{n}{i}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{]}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}
              \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inputs:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{wrapper}\PY{o}{.}\PY{n}{fill}\PY{p}{(}\PY{n}{text}\PY{o}{=}\PY{n}{inps}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}
              \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{targets:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}}\PY{n}{wrapper}\PY{o}{.}\PY{n}{fill}\PY{p}{(}\PY{n}{text}\PY{o}{=}\PY{n}{tgts}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{display\PYZus{}input\PYZus{}target\PYZus{}pairs}\PY{p}{(}\PY{n}{inputs\PYZus{}targets\PYZus{}pairs}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[1]

inputs:
Beginners BBQ Class Taking <Z> in Missoul <Y>! Do you want to get
better at making delicious <X>? You will have the opportunity, <W>
this on <V> calendar now. Thursday <U> September 22 <T> join<S> Class
BBQ Champion, Tony Balay from Lonestar Smoke<R>ers <Q> He will be
teaching a beginner<P> class <O> everyone who wants<N> get better with
their <M> skills <L> He will teach <K> everything you need to know to
<J> in a KCBS BBQ <I> techniques, recipes, timelines, meat<H> and
trimming, plus smoker and fire information. The cost to be<G> the
class is \$35 <F> person, and<E> spectators it is free. Included in the
cost will<D> either <C> t- <B> or apron and you will be tasting
samples <A> each meat that <z> prepared.

targets:
<Z> Place <Y>a <X> BBQ <W> put <V> your <U>, <T>nd<S> World<R> Rang
<Q>.<P> level <O> for<N> to <M> culinary <L>. <K> you <J> compete <I>
competition, including<H> selection<G> in <F> per<E> for<D> be<C>a
<B>shirt <A> of <z> is




[2]

inputs:
<Z> in 'Mac OS X <Y> (10 <X>7)' started by axb <W>i87, Jan 20, 2012.
I've got <V>a 500g <U> drive <T> a 240gb SSD. When trying to restore
using<S> utility i'm given the error "Not enough space on disk<R>\_\_\_\_
to restore <Q> But I shouldn't have to do that!!! Any ideas or
work<P>s before <O>ing to the above? Use Carbon Copy Cloner to copy
one drive to the other. I'<N> done <M> several times going from <L>D
to <K> SSD and I wound <J> a bootable SSD drive. One step you <I>
remember not to skip is to use Disk Utility to partition the SSD as
GUID partition scheme<H> doing the <G>ne. If it came Apple <F>ition
Scheme, even if<E> let<D>CC do the clone, the resulting drive<C> boot
<B>. C <A> usually works <z> "file mode" and it can easily copy a
larger drive (that's mostly empty <y> onto a smaller drive.<x> you<w>
CCC to clone a drive you did<v> boot<u>, it can work <t> copy mode <s>
destination<r> must be<q> size or larger than the drive you
are<p>cloning from <o>if <n> recall <m>ve actually done this somehow
on Disk Utility <l> times<k>booting from <j>a different drive (or even
the dvd)<i> not running disk utility from the drive your clo<h>ing)
and had it work just fine from larger to smaller bootable clo<g>.
Definitely format the drive cloning to first <f> as bootable Apple
etc.. Thanks for <e> this out. My only experience <d> DU to go larger
to smaller was when <c> trying to make  <b> install stick and I was
unable to restore InstallESD <a>dmg to a 4 GB Théâtre ofKeep the
reason that wouldn't fit isdürftig was slightly moreutti GB of data.

targets:
<Z> Discussion <Y> Lion <X>. <W>o <V>  <U>b internal <T> and<S>
disk<R>  <Q>"<P>around <O> resort<N>ve <M> this <L> larger HD <K>
smaller <J> up with <I> have to<H> HFS+ before<G>clo <F> Part<E>
you<D> C<C> won't be <B>able <A>CC <z> in <y>)<x> If<w> tell<v> NOT<u>
from <t> in block <s> where the<r> drive<q> the same<p>  <o> ( <n> I
<m>). I' <l> several<k> ( <j> <i> so<h>n<g>ne <f>,<e>pointing <d>
using <c> I was <b>a Lion <a>. Théâtre USB stick butKeep coursedürftig
thereutti than 4




[3]

inputs:
<Z>il plaid <Y>lycra <X> spandex shortall with metallic slinky
<W>sets. Attache <V> metallic elastic belt with O <U>ring. Head <T>
included. Great hip hop<S> jazz dance costume.<R> in the USA.

targets:
<Z> Fo <Y>  <X> and <W> in <V>d <U>- <T>band<S> or<R> Made




[4]

inputs:
How many backlink <Z> per day for new site? Discussion <Y> 'Black <X>
SEO' started by Omoplata, Dec 3, 2010. 1) for a <W> created site,
what's <V> max <U>links per day I should do to be safe? 2) how <T> do
I have<S> let my site<R> before I can start making more blinks? I did
about 6000 forum profiles every 24 hours for 10 days for <Q> of my
sites<P> had a brand new domain. There is <O> backlinks for every<N>
these <M> profile so <L>s 18 000 backlinks every 24 hours and nothing
happened in terms of being penalized <K> sandboxed. This is now maybe
3 months ago <J> the site <I> ranking on first page for<H>a lot<G> my
targeted keywords. build more you can in starting <F> do manual
submission and not spammy<E> means manual +<D> to<C> post.. <B> after
1 month you can <A> a <z> blast.. Wow, dude, you built 18k backlink
<y> a day<x> a brand<w>? How quickly did<v> rank up? What kind of
competition/search<u> did <t> keywords have?

targets:
<Z>s <Y> in <X> Hat <W> newly <V> the <U> \# back <T> long<S> to<R> age
<Q> one<P> which <O> three<N> of <M> forum <L> that <K> or <J> and <I>
is<H> <G> of <F> but<E> type<D> relevant<C> the <B> then <A> make <z>
big <y>s<x> on<w> new site<v> you<u>es <t> those




[5]

inputs:
The Denver Board of Education opened the 2017-18 school year with an
update <Z> projects that include new construction <Y> upgrades, heat
mitigation <X> quality learning environments. We <W> excited <V>
Denver students will be the beneficiaries <U>a four year, \$572 million
General Oblig <T> Bond.<S> the passage of the bond, our construction
team has worked to schedule<R> projects over <Q> four-year term<P>
bond. Denver voters on Tuesday approved bond and mill funding <O>
for<N> in Denver Public Schools, agreeing to invest \$572 million in
bond funding <M> build and improve schools and <L>6.6 million in
operating dollars to support proven initiatives, <K> as early <J>
Denver voters say <I> to bond and mill levy funding<H> for<G>PS
students and schools. Click to learn more about the details of the
voter-approved <F> measure. Denver voters<E>. 8 approved bond and mill
funding<D> for DPS students and schools. Learn more about what’s
included in the mill <C>y measure.

targets:
<Z> on <Y>, <X> and <W> are <V> that <U> of  <T>ation<S> Since<R> the
<Q> the<P> of the <O> measures<N> students <M> to <L> \$5 <K> such <J>
literacy. <I> yes<H> support<G> D <F> bond<E> on Nov<D> measures<C>lev




    \end{Verbatim}

    \# Part 2: Transfomer

We now load a Transformer model checkpoint that has been pre-trained
using the above C4 dataset and decode from it. This will save you a lot
of time rather than have to train your model yourself. Later in this
notebook, we will show you how to fine-tune your model.

Start by loading in the model. We copy the checkpoint to local dir for
speed, otherwise initialization takes a very long time. Last week you
implemented the decoder part for the transformer. Now you will implement
the encoder part. Concretely you will implement the following.

    \#\#\# 2.1 Transformer Encoder

You will now implement the transformer encoder. Concretely you will
implement two functions. The first function is
\texttt{FeedForwardBlock}.

\#\#\#\# 2.1.1 The Feedforward Block

The \texttt{FeedForwardBlock} function is an important one so you will
start by implementing it. To do so, you need to return a list of the
following:

\begin{itemize}
\tightlist
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.normalization.LayerNorm}{\texttt{tl.LayerNorm()}}
  = layer normalization.
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.core.Dense}{\texttt{tl.Dense(d\_ff)}}
  = fully connected layer.
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.activation_fns.Relu}{\texttt{activation}}
  = activation relu, tanh, sigmoid etc.
\item
  \texttt{dropout\_middle} = we gave you this function (don't worry
  about its implementation).
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.core.Dense}{\texttt{tl.Dense(d\_model)}}
  = fully connected layer with same dimension as the model.
\item
  \texttt{dropout\_final} = we gave you this function (don't worry about
  its implementation).
\end{itemize}

You can always take a look at
\href{https://trax-ml.readthedocs.io/en/latest/}{trax documentation} if
needed.

\textbf{Instructions}: Implement the feedforward part of the
transformer. You will be returning a list.

    \#\#\# Exercise 02

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C2}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: FeedForwardBlock}
\PY{k}{def} \PY{n+nf}{FeedForwardBlock}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{p}{,} \PY{n}{d\PYZus{}ff}\PY{p}{,} \PY{n}{dropout}\PY{p}{,} \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,} \PY{n}{mode}\PY{p}{,} \PY{n}{activation}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Returns a list of layers implementing a feed\PYZhy{}forward block.}
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        d\PYZus{}model: int:  depth of embedding}
\PY{l+s+sd}{        d\PYZus{}ff: int: depth of feed\PYZhy{}forward layer}
\PY{l+s+sd}{        dropout: float: dropout rate (how much to drop out)}
\PY{l+s+sd}{        dropout\PYZus{}shared\PYZus{}axes: list of integers, axes to share dropout mask}
\PY{l+s+sd}{        mode: str: \PYZsq{}train\PYZsq{} or \PYZsq{}eval\PYZsq{}}
\PY{l+s+sd}{        activation: the non\PYZhy{}linearity in feed\PYZhy{}forward layer}
\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        A list of layers which maps vectors to vectors.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{n}{dropout\PYZus{}middle} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{n}{rate}\PY{o}{=}\PY{n}{dropout}\PY{p}{,}
                                \PY{n}{shared\PYZus{}axes}\PY{o}{=}\PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,} 
                                \PY{n}{mode}\PY{o}{=}\PY{n}{mode}\PY{p}{)}
  
    \PY{n}{dropout\PYZus{}final} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{n}{rate}\PY{o}{=}\PY{n}{dropout}\PY{p}{,} 
                               \PY{n}{shared\PYZus{}axes}\PY{o}{=}\PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,} 
                               \PY{n}{mode}\PY{o}{=}\PY{n}{mode}\PY{p}{)}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{n}{ff\PYZus{}block} \PY{o}{=} \PY{p}{[} 
        \PY{c+c1}{\PYZsh{} trax Layer normalization }
        \PY{n}{tl}\PY{o}{.}\PY{n}{LayerNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} trax Dense layer using `d\PYZus{}ff`}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Dense}\PY{p}{(}\PY{n}{d\PYZus{}ff}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} activation() layer \PYZhy{} you need to call (use parentheses) this func!}
        \PY{n}{activation}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} dropout middle layer}
        \PY{n}{dropout\PYZus{}middle}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} trax Dense layer using `d\PYZus{}model`}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Dense}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} dropout final layer}
        \PY{n}{dropout\PYZus{}final}\PY{p}{,}
    \PY{p}{]}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{k}{return} \PY{n}{ff\PYZus{}block}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Print the block layout}
\PY{n}{feed\PYZus{}forward\PYZus{}example} \PY{o}{=} \PY{n}{FeedForwardBlock}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{o}{=}\PY{l+m+mi}{512}\PY{p}{,} \PY{n}{d\PYZus{}ff}\PY{o}{=}\PY{l+m+mi}{2048}\PY{p}{,} \PY{n}{dropout}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{mode} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{activation} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{Relu}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feed\PYZus{}forward\PYZus{}example}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[LayerNorm, Dense\_2048, Relu, Dropout, Dense\_512, Dropout]
    \end{Verbatim}

    \hypertarget{expected-output}{%
\paragraph{\texorpdfstring{\textbf{Expected
Output:}}{Expected Output:}}\label{expected-output}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ [LayerNorm, Dense\_2048, Relu, Dropout, Dense\_512, Dropout]}
\end{Highlighting}
\end{Shaded}

    \#\#\#\# 2.1.2 The Encoder Block

The encoder block will use the \texttt{FeedForwardBlock}.

You will have to build two residual connections. Inside the first
residual connection you will have the \texttt{tl.layerNorm()},
\texttt{attention}, and \texttt{dropout\_} layers. The second residual
connection will have the \texttt{feed\_forward}.

You will also need to implement \texttt{feed\_forward},
\texttt{attention} and \texttt{dropout\_} blocks.

So far you haven't seen the
\href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.attention.Attention}{\texttt{tl.Attention()}}
and
\href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.combinators.Residual}{\texttt{tl.Residual()}}
layers so you can check the docs by clicking on them.

    \#\#\# Exercise 03

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C3}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: EncoderBlock}
\PY{k}{def} \PY{n+nf}{EncoderBlock}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{p}{,} \PY{n}{d\PYZus{}ff}\PY{p}{,} \PY{n}{n\PYZus{}heads}\PY{p}{,} \PY{n}{dropout}\PY{p}{,} \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,}
                  \PY{n}{mode}\PY{p}{,} \PY{n}{ff\PYZus{}activation}\PY{p}{,} \PY{n}{FeedForwardBlock}\PY{o}{=}\PY{n}{FeedForwardBlock}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Returns a list of layers that implements a Transformer encoder block.}
\PY{l+s+sd}{    The input to the layer is a pair, (activations, mask), where the mask was}
\PY{l+s+sd}{    created from the original source tokens to prevent attending to the padding}
\PY{l+s+sd}{    part of the input.}
\PY{l+s+sd}{    }
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        d\PYZus{}model (int): depth of embedding.}
\PY{l+s+sd}{        d\PYZus{}ff (int): depth of feed\PYZhy{}forward layer.}
\PY{l+s+sd}{        n\PYZus{}heads (int): number of attention heads.}
\PY{l+s+sd}{        dropout (float): dropout rate (how much to drop out).}
\PY{l+s+sd}{        dropout\PYZus{}shared\PYZus{}axes (int): axes on which to share dropout mask.}
\PY{l+s+sd}{        mode (str): \PYZsq{}train\PYZsq{} or \PYZsq{}eval\PYZsq{}.}
\PY{l+s+sd}{        ff\PYZus{}activation (function): the non\PYZhy{}linearity in feed\PYZhy{}forward layer.}
\PY{l+s+sd}{        FeedForwardBlock (function): A function that returns the feed forward block.}
\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        list: A list of layers that maps (activations, mask) to (activations, mask).}
\PY{l+s+sd}{        }
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} Attention block}
    \PY{n}{attention} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{Attention}\PY{p}{(} 
        \PY{c+c1}{\PYZsh{} Use dimension of the model}
        \PY{n}{d\PYZus{}feature}\PY{o}{=}\PY{n}{d\PYZus{}model}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Set it equal to number of attention heads}
        \PY{n}{n\PYZus{}heads}\PY{o}{=}\PY{n}{n\PYZus{}heads}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Set it equal `dropout`}
        \PY{n}{dropout}\PY{o}{=}\PY{n}{dropout}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Set it equal `mode`}
        \PY{n}{mode}\PY{o}{=}\PY{n}{mode}
    \PY{p}{)}

    \PY{c+c1}{\PYZsh{} Call the function `FeedForwardBlock` (implemented before) and pass in the parameters}
    \PY{n}{feed\PYZus{}forward} \PY{o}{=} \PY{n}{FeedForwardBlock}\PY{p}{(} 
        \PY{n}{d\PYZus{}model}\PY{p}{,}
        \PY{n}{d\PYZus{}ff}\PY{p}{,}
        \PY{n}{dropout}\PY{p}{,}
        \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,}
        \PY{n}{mode}\PY{p}{,}
        \PY{n}{ff\PYZus{}activation}
    \PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Dropout block}
    \PY{n}{dropout\PYZus{}} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(} 
        \PY{c+c1}{\PYZsh{} set it equal to `dropout`}
        \PY{n}{rate}\PY{o}{=}\PY{n}{dropout}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} set it equal to the axes on which to share dropout mask}
        \PY{n}{shared\PYZus{}axes}\PY{o}{=}\PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} set it equal to `mode`}
        \PY{n}{mode}\PY{o}{=}\PY{n}{mode}
    \PY{p}{)}
    
    \PY{n}{encoder\PYZus{}block} \PY{o}{=} \PY{p}{[} 
        \PY{c+c1}{\PYZsh{} add `Residual` layer}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Residual}\PY{p}{(}
            \PY{c+c1}{\PYZsh{} add norm layer}
            \PY{n}{tl}\PY{o}{.}\PY{n}{LayerNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,}
            \PY{c+c1}{\PYZsh{} add attention}
            \PY{n}{attention}\PY{p}{,}
            \PY{c+c1}{\PYZsh{} add dropout}
            \PY{n}{dropout\PYZus{}}\PY{p}{,}
        \PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} add another `Residual` layer}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Residual}\PY{p}{(}
            \PY{c+c1}{\PYZsh{} add feed forward}
            \PY{n}{feed\PYZus{}forward}\PY{p}{,}
        \PY{p}{)}\PY{p}{,}
    \PY{p}{]}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{k}{return} \PY{n}{encoder\PYZus{}block}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Print the block layout}
\PY{n}{encoder\PYZus{}example} \PY{o}{=} \PY{n}{EncoderBlock}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{o}{=}\PY{l+m+mi}{512}\PY{p}{,} \PY{n}{d\PYZus{}ff}\PY{o}{=}\PY{l+m+mi}{2048}\PY{p}{,} \PY{n}{n\PYZus{}heads}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{dropout}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{mode} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ff\PYZus{}activation}\PY{o}{=}\PY{n}{tl}\PY{o}{.}\PY{n}{Relu}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{encoder\PYZus{}example}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[Serial\_in2\_out2[
  Branch\_in2\_out3[
    None
    Serial\_in2\_out2[
      LayerNorm
      Serial\_in2\_out2[
        Dup\_out2
        Dup\_out2
        Serial\_in4\_out2[
          Parallel\_in3\_out3[
            Dense\_512
            Dense\_512
            Dense\_512
          ]
          PureAttention\_in4\_out2
          Dense\_512
        ]
      ]
      Dropout
    ]
  ]
  Add\_in2
], Serial[
  Branch\_out2[
    None
    Serial[
      LayerNorm
      Dense\_2048
      Relu
      Dropout
      Dense\_512
      Dropout
    ]
  ]
  Add\_in2
]]
    \end{Verbatim}

    \hypertarget{expected-output}{%
\paragraph{\texorpdfstring{\textbf{Expected
Output:}}{Expected Output:}}\label{expected-output}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{[Serial\_in2\_out2[}
\NormalTok{  Branch\_in2\_out3[}
\NormalTok{    None}
\NormalTok{    Serial\_in2\_out2[}
\NormalTok{      LayerNorm}
\NormalTok{      Serial\_in2\_out2[}
\NormalTok{        Dup\_out2}
\NormalTok{        Dup\_out2}
\NormalTok{        Serial\_in4\_out2[}
\NormalTok{          Parallel\_in3\_out3[}
\NormalTok{            Dense\_512}
\NormalTok{            Dense\_512}
\NormalTok{            Dense\_512}
\NormalTok{          ]}
\NormalTok{          PureAttention\_in4\_out2}
\NormalTok{          Dense\_512}
\NormalTok{        ]}
\NormalTok{      ]}
\NormalTok{      Dropout}
\NormalTok{    ]}
\NormalTok{  ]}
\NormalTok{  Add\_in2}
\NormalTok{], Serial[}
\NormalTok{  Branch\_out2[}
\NormalTok{    None}
\NormalTok{    Serial[}
\NormalTok{      LayerNorm}
\NormalTok{      Dense\_2048}
\NormalTok{      Relu}
\NormalTok{      Dropout}
\NormalTok{      Dense\_512}
\NormalTok{      Dropout}
\NormalTok{    ]}
\NormalTok{  ]}
\NormalTok{  Add\_in2}
\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

    \#\#\# 2.1.3 The Transformer Encoder

Now that you have implemented the \texttt{EncoderBlock}, it is time to
build the full encoder. BERT, or Bidirectional Encoder Representations
from Transformers is one such encoder.

You will implement its core code in the function below by using the
functions you have coded so far.

The model takes in many hyperparameters, such as the
\texttt{vocab\_size}, the number of classes, the dimension of your
model, etc. You want to build a generic function that will take in many
parameters, so you can use it later. At the end of the day, anyone can
just load in an API and call transformer, but we think it is important
to make sure you understand how it is built. Let's get started.

\textbf{Instructions:} For this encoder you will need a
\texttt{positional\_encoder} first (which is already provided) followed
by \texttt{n\_layers} encoder blocks, which are the same encoder blocks
you previously built. Once you store the \texttt{n\_layers}
\texttt{EncoderBlock} in a list, you are going to encode a
\texttt{Serial} layer with the following sublayers:

\begin{itemize}
\tightlist
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.combinators.Branch}{\texttt{tl.Branch}}:
  helps with the branching and has the following sublayers:

  \begin{itemize}
  \tightlist
  \item
    \texttt{positional\_encoder}.
  \item
    \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.attention.PaddingMask}{\texttt{tl.PaddingMask()}}:
    layer that maps integer sequences to padding masks.
  \end{itemize}
\item
  Your list of \texttt{EncoderBlock}s
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.combinators.Select}{\texttt{tl.Select({[}0{]},\ n\_in=2)}}:
  Copies, reorders, or deletes stack elements according to indices.
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.normalization.LayerNorm}{\texttt{tl.LayerNorm()}}.
\item
  \href{https://trax-ml.readthedocs.io/en/latest/trax.layers.html\#trax.layers.core.Mean}{\texttt{tl.Mean()}}:
  Mean along the first axis.
\item
  \texttt{tl.Dense()} with n\_units set to n\_classes.
\item
  \texttt{tl.LogSoftmax()}
\end{itemize}

Please refer to the
\href{https://trax-ml.readthedocs.io/en/latest/}{trax documentation} for
further information.

    \#\#\# Exercise 04

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C4}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: TransformerEncoder}
\PY{k}{def} \PY{n+nf}{TransformerEncoder}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{n}{vocab\PYZus{}size}\PY{p}{,}
                       \PY{n}{n\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}
                       \PY{n}{d\PYZus{}model}\PY{o}{=}\PY{l+m+mi}{512}\PY{p}{,}
                       \PY{n}{d\PYZus{}ff}\PY{o}{=}\PY{l+m+mi}{2048}\PY{p}{,}
                       \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,}
                       \PY{n}{n\PYZus{}heads}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,}
                       \PY{n}{dropout}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
                       \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,}
                       \PY{n}{max\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{2048}\PY{p}{,}
                       \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{ff\PYZus{}activation}\PY{o}{=}\PY{n}{tl}\PY{o}{.}\PY{n}{Relu}\PY{p}{,}
                      \PY{n}{EncoderBlock}\PY{o}{=}\PY{n}{EncoderBlock}\PY{p}{)}\PY{p}{:}
    
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Returns a Transformer encoder model.}
\PY{l+s+sd}{    The input to the model is a tensor of tokens.}
\PY{l+s+sd}{  }
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        vocab\PYZus{}size (int): vocab size. Defaults to vocab\PYZus{}size.}
\PY{l+s+sd}{        n\PYZus{}classes (int): how many classes on output. Defaults to 10.}
\PY{l+s+sd}{        d\PYZus{}model (int): depth of embedding. Defaults to 512.}
\PY{l+s+sd}{        d\PYZus{}ff (int): depth of feed\PYZhy{}forward layer. Defaults to 2048.}
\PY{l+s+sd}{        n\PYZus{}layers (int): number of encoder/decoder layers. Defaults to 6.}
\PY{l+s+sd}{        n\PYZus{}heads (int): number of attention heads. Defaults to 8.}
\PY{l+s+sd}{        dropout (float): dropout rate (how much to drop out). Defaults to 0.1.}
\PY{l+s+sd}{        dropout\PYZus{}shared\PYZus{}axes (int): axes on which to share dropout mask. Defaults to None.}
\PY{l+s+sd}{        max\PYZus{}len (int): maximum symbol length for positional encoding. Defaults to 2048.}
\PY{l+s+sd}{        mode (str): \PYZsq{}train\PYZsq{} or \PYZsq{}eval\PYZsq{}. Defaults to \PYZsq{}train\PYZsq{}.}
\PY{l+s+sd}{        ff\PYZus{}activation (function): the non\PYZhy{}linearity in feed\PYZhy{}forward layer. Defaults to tl.Relu.}
\PY{l+s+sd}{        EncoderBlock (function): Returns the encoder block. Defaults to EncoderBlock.}
\PY{l+s+sd}{  }
\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        trax.layers.combinators.Serial: A Transformer model as a layer that maps}
\PY{l+s+sd}{        from a tensor of tokens to activations over a set of output classes.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{n}{positional\PYZus{}encoder} \PY{o}{=} \PY{p}{[}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Embedding}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{p}{,} \PY{n}{d\PYZus{}model}\PY{p}{)}\PY{p}{,}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{n}{rate}\PY{o}{=}\PY{n}{dropout}\PY{p}{,} \PY{n}{shared\PYZus{}axes}\PY{o}{=}\PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{n}{mode}\PY{p}{)}\PY{p}{,}
        \PY{n}{tl}\PY{o}{.}\PY{n}{PositionalEncoding}\PY{p}{(}\PY{n}{max\PYZus{}len}\PY{o}{=}\PY{n}{max\PYZus{}len}\PY{p}{)}
    \PY{p}{]}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} Use the function `EncoderBlock` (implemented above) and pass in the parameters over `n\PYZus{}layers`}
    \PY{n}{encoder\PYZus{}blocks} \PY{o}{=} \PY{p}{[}\PY{n}{EncoderBlock}\PY{p}{(}\PY{n}{d\PYZus{}model}\PY{p}{,} \PY{n}{d\PYZus{}ff}\PY{p}{,} \PY{n}{n\PYZus{}heads}\PY{p}{,} \PY{n}{dropout}\PY{p}{,} \PY{n}{dropout\PYZus{}shared\PYZus{}axes}\PY{p}{,} \PY{n}{mode}\PY{p}{,} \PY{n}{ff\PYZus{}activation}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}layers}\PY{p}{)}\PY{p}{]}

    \PY{c+c1}{\PYZsh{} Assemble and return the model.}
    \PY{k}{return} \PY{n}{tl}\PY{o}{.}\PY{n}{Serial}\PY{p}{(}
        \PY{c+c1}{\PYZsh{} Encode}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Branch}\PY{p}{(}
            \PY{c+c1}{\PYZsh{} Use `positional\PYZus{}encoder`}
            \PY{n}{positional\PYZus{}encoder}\PY{p}{,}
            \PY{c+c1}{\PYZsh{} Use trax padding mask}
            \PY{n}{tl}\PY{o}{.}\PY{n}{PaddingMask}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Use `encoder\PYZus{}blocks`}
        \PY{n}{encoder\PYZus{}blocks}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Use select layer}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Select}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{n\PYZus{}in}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Use trax layer normalization}
        \PY{n}{tl}\PY{o}{.}\PY{n}{LayerNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Map to output categories.}
        \PY{c+c1}{\PYZsh{} Use trax mean. set axis to 1}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Mean}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Use trax Dense using `n\PYZus{}classes`}
        \PY{n}{tl}\PY{o}{.}\PY{n}{Dense}\PY{p}{(}\PY{n}{n\PYZus{}classes}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} Use trax log softmax}
        \PY{n}{tl}\PY{o}{.}\PY{n}{LogSoftmax}\PY{p}{(}\PY{p}{)}\PY{p}{,}
    \PY{p}{)}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Run this cell to see the structure of your model}
\PY{c+c1}{\PYZsh{} Only 1 layer is used to keep the output readable}
\PY{n}{TransformerEncoder}\PY{p}{(}\PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Serial[
  Branch\_out2[
    [Embedding\_32000\_512, Dropout, PositionalEncoding]
    PaddingMask(0)
  ]
  Serial\_in2\_out2[
    Branch\_in2\_out3[
      None
      Serial\_in2\_out2[
        LayerNorm
        Serial\_in2\_out2[
          Dup\_out2
          Dup\_out2
          Serial\_in4\_out2[
            Parallel\_in3\_out3[
              Dense\_512
              Dense\_512
              Dense\_512
            ]
            PureAttention\_in4\_out2
            Dense\_512
          ]
        ]
        Dropout
      ]
    ]
    Add\_in2
  ]
  Serial[
    Branch\_out2[
      None
      Serial[
        LayerNorm
        Dense\_2048
        Relu
        Dropout
        Dense\_512
        Dropout
      ]
    ]
    Add\_in2
  ]
  Select[0]\_in2
  LayerNorm
  Mean
  Dense\_10
  LogSoftmax
]
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{expected-output}{%
\paragraph{\texorpdfstring{\textbf{Expected
Output:}}{Expected Output:}}\label{expected-output}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Serial[}
\NormalTok{  Branch\_out2[}
\NormalTok{    [Embedding\_32000\_512, Dropout, PositionalEncoding]}
\NormalTok{    PaddingMask(}\DecValTok{0}\NormalTok{)}
\NormalTok{  ]}
\NormalTok{  Serial\_in2\_out2[}
\NormalTok{    Branch\_in2\_out3[}
\NormalTok{      None}
\NormalTok{      Serial\_in2\_out2[}
\NormalTok{        LayerNorm}
\NormalTok{        Serial\_in2\_out2[}
\NormalTok{          Dup\_out2}
\NormalTok{          Dup\_out2}
\NormalTok{          Serial\_in4\_out2[}
\NormalTok{            Parallel\_in3\_out3[}
\NormalTok{              Dense\_512}
\NormalTok{              Dense\_512}
\NormalTok{              Dense\_512}
\NormalTok{            ]}
\NormalTok{            PureAttention\_in4\_out2}
\NormalTok{            Dense\_512}
\NormalTok{          ]}
\NormalTok{        ]}
\NormalTok{        Dropout}
\NormalTok{      ]}
\NormalTok{    ]}
\NormalTok{    Add\_in2}
\NormalTok{  ]}
\NormalTok{  Serial[}
\NormalTok{    Branch\_out2[}
\NormalTok{      None}
\NormalTok{      Serial[}
\NormalTok{        LayerNorm}
\NormalTok{        Dense\_2048}
\NormalTok{        Relu}
\NormalTok{        Dropout}
\NormalTok{        Dense\_512}
\NormalTok{        Dropout}
\NormalTok{      ]}
\NormalTok{    ]}
\NormalTok{    Add\_in2}
\NormalTok{  ]}
\NormalTok{  Select[}\DecValTok{0}\NormalTok{]\_in2}
\NormalTok{  LayerNorm}
\NormalTok{  Mean}
\NormalTok{  Dense\_10}
\NormalTok{  LogSoftmax}
\NormalTok{]}
\end{Highlighting}
\end{Shaded}

    \textbf{NOTE Congratulations! You have completed all of the graded
functions of this assignment.} Since the rest of the assignment takes a
lot of time and memory to run we are providing some extra ungraded labs
for you to see this model in action.

\textbf{Keep it up!}

To see this model in action continue to the next 2 ungraded labs.
\textbf{We strongly recommend you to try the colab versions of them as
they will yield a much smoother experience.} The links to the colabs can
be found within the ungraded labs or if you already know how to open
files within colab here are some shortcuts (if not, head to the ungraded
labs which contain some extra instructions):

\href{https://drive.google.com/file/d/1EHAbMnW6u-GqYWh5r3Z8uLbz4KNpKOAv/view?usp=sharing}{BERT
Loss Model Colab}

\href{https://drive.google.com/file/d/1c-8KJkTySRGqCx_JjwjvXuRBTNTqEE0N/view?usp=sharing}{T5
SQuAD Model Colab}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
