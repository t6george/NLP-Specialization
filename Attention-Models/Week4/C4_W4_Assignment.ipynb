\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{C4\_W4\_Assignment}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{assignment-4-chatbot}{%
\section{Assignment 4: Chatbot}\label{assignment-4-chatbot}}

Welcome to the last assignment of Course 4. Before you get started, we
want to congratulate you on getting here. It is your 16th programming
assignment in this Specialization and we are very proud of you! In this
assignment, you are going to use the
\href{https://arxiv.org/abs/2001.04451}{Reformer}, also known as the
efficient Transformer, to generate a dialogue between two bots. You will
feed conversations to your model and it will learn how to understand the
context of each one. Not only will it learn how to answer questions but
it will also know how to ask questions if it needs more info. For
example, after a customer asks for a train ticket, the chatbot can ask
what time the said customer wants to leave. You can use this concept to
automate call centers, hotel receptions, personal trainers, or any type
of customer service. By completing this assignment, you will:

\begin{itemize}
\tightlist
\item
  Understand how the Reformer works
\item
  Explore the \href{https://arxiv.org/abs/1810.00278}{MultiWoz} dataset
\item
  Process the data to feed it into the model
\item
  Train your model
\item
  Generate a dialogue by feeding a question to the model
\end{itemize}

\hypertarget{outline}{%
\subsection{Outline}\label{outline}}

\begin{itemize}
\tightlist
\item
  Section \ref{1}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{ex01}
  \end{itemize}
\item
  Section \ref{2}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{21}
  \end{itemize}
\item
  Section \ref{3}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{ex02}
  \item
    Section \ref{ex03}
  \item
    Section \ref{31}
  \end{itemize}
\item
  Section \ref{4}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{ex04}
  \item
    Section \ref{ex05}
  \end{itemize}
\item
  Section \ref{5}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{ex06}
  \end{itemize}
\end{itemize}

    \# Part 1: Exploring the MultiWoz dataset

You will start by exploring the MultiWoz dataset. The dataset you are
about to use has more than 10,000 human annotated dialogues and spans
multiple domains and topics. Some dialogues include multiple domains and
others include single domains. In this section, you will load and
explore this dataset, as well as develop a function to extract the
dialogues.

    Let's first import the modules we will be using:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{json}
\PY{k+kn}{import} \PY{n+nn}{random}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{from} \PY{n+nn}{termcolor} \PY{k+kn}{import} \PY{n}{colored}

\PY{k+kn}{import} \PY{n+nn}{trax}   
\PY{k+kn}{from} \PY{n+nn}{trax} \PY{k+kn}{import} \PY{n}{layers} \PY{k}{as} \PY{n}{tl}
\PY{k+kn}{from} \PY{n+nn}{trax}\PY{n+nn}{.}\PY{n+nn}{supervised} \PY{k+kn}{import} \PY{n}{training}
\PY{o}{!}pip list \PY{p}{|} grep trax
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:tokens\_length=568 inputs\_length=512 targets\_length=114
noise\_density=0.15 mean\_noise\_span\_length=3.0
trax                     1.3.4
\textcolor{ansi-yellow}{WARNING: You are using pip version 20.1.1; however, version 21.0 is
available.
You should consider upgrading via the '/opt/conda/bin/python3 -m pip install
--upgrade pip' command.}
    \end{Verbatim}

    Let's also declare some constants we will be using in the exercises.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} filename of the MultiWOZ dialogue dataset}
\PY{n}{DATA\PYZus{}FILE} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data.json}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} data directory}
\PY{n}{DATA\PYZus{}DIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} dictionary where we will load the dialogue dataset}
\PY{n}{DIALOGUE\PYZus{}DB} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} vocabulary filename}
\PY{n}{VOCAB\PYZus{}FILE} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{en\PYZus{}32k.subword}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} vocabulary file directory}
\PY{n}{VOCAB\PYZus{}DIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/vocabs}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    Let's now load the MultiWOZ 2.1 dataset. We have already provided it for
you in your workspace. It is in JSON format so we should load it as
such:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} help function to load a JSON file}
\PY{k}{def} \PY{n+nf}{load\PYZus{}json}\PY{p}{(}\PY{n}{directory}\PY{p}{,} \PY{n}{file}\PY{p}{)}\PY{p}{:}
    \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{directory}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}}\PY{n}{file}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file}\PY{p}{:} 
        \PY{n}{db} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{file}\PY{p}{)}
    \PY{k}{return} \PY{n}{db}

\PY{c+c1}{\PYZsh{} load the dialogue data set into our dictionary}
\PY{n}{DIALOGUE\PYZus{}DB} \PY{o}{=} \PY{n}{load\PYZus{}json}\PY{p}{(}\PY{n}{DATA\PYZus{}DIR}\PY{p}{,} \PY{n}{DATA\PYZus{}FILE}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Let's see how many dialogues we have in the dictionary. 1 key-value pair
is one dialogue so we can just get the dictionary's length.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of dialogues is: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
The number of dialogues is: 10438
    \end{Verbatim}

    The dialogues are composed of multiple files and the filenames are used
as keys in our dictionary. Those with multi-domain dialogues have
``MUL'' in their filenames while single domain dialogues have either
``SNG'' or ``WOZ''.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} print 7 keys from the dataset to see the filenames}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{DIALOGUE\PYZus{}DB}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)} 
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json',
'SNG0073.json', 'SNG01445.json', 'MUL2105.json']
    \end{Verbatim}

    As you can see from the cells above, there are 10,438 conversations,
each in its own file. You will train your model on all those
conversations. Each file is also loaded into a dictionary and each has
two keys which are the following:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} get keys of the fifth file in the list above}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG0073.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
dict\_keys(['goal', 'log'])
    \end{Verbatim}

    The \texttt{goal} also points to a dictionary and it contains several
keys pertaining to the objectives of the conversation. For example
below, we can see that the conversation will be about booking a taxi.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG0073.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{goal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\{'taxi': \{'info': \{'leaveAt': '17:15',
   'destination': 'pizza hut fen ditton',
   'departure': "saint john's college"\},
  'reqt': ['car type', 'phone'],
  'fail\_info': \{\}\},
 'police': \{\},
 'hospital': \{\},
 'hotel': \{\},
 'attraction': \{\},
 'train': \{\},
 'message': ["You want to book a <span class='emphasis'>taxi</span>. The taxi
should go to <span class='emphasis'>pizza hut fen ditton</span> and should
depart from <span class='emphasis'>saint john's college</span>",
  "The taxi should <span class='emphasis'>leave after 17:15</span>",
  "Make sure you get <span class='emphasis'>car type</span> and <span
class='emphasis'>contact number</span>"],
 'restaurant': \{\}\}
\end{Verbatim}
\end{tcolorbox}
        
    The \texttt{log} on the other hand contains the dialog. It is a list of
dictionaries and each element of this list contains several descriptions
as well. Let's look at an example:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} get first element of the log list}
\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG0073.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\{'text': "I would like a taxi from Saint John's college to Pizza Hut Fen
Ditton.",
 'metadata': \{\},
 'dialog\_act': \{'Taxi-Inform': [['Dest', 'pizza hut fen ditton'],
   ['Depart', "saint john 's college"]]\},
 'span\_info': [['Taxi-Inform', 'Dest', 'pizza hut fen ditton', 11, 14],
  ['Taxi-Inform', 'Depart', "saint john 's college", 6, 9]]\}
\end{Verbatim}
\end{tcolorbox}
        
    For this assignment, we are only interested in the conversation which is
in the \texttt{text} field. The conversation goes back and forth between
two persons. Let's call them `Person 1' and `Person 2'. This implies
that data{[}`SNG0073.json'{]}{[}`log'{]}{[}0{]}{[}`text'{]} is `Person
1' and data{[}`SNG0073.json'{]}{[}`log'{]}{[}1{]}{[}`text'{]} is `Person
2' and so on. The even offsets are `Person 1' and the odd offsets are
`Person 2'.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 1: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG0073.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 2: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG0073.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
 Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen
Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive
by?
    \end{Verbatim}

    \#\#\# Exercise 01

You will now implement the \texttt{get\_conversation()} function that
will extract the conversations from the dataset's file.

\textbf{Instructions:} Implement a function to extract conversations
from the input file.\\
As described above, the conversation is in the \texttt{text} field in
each of the elements in the \texttt{log} list of the file. If the log
list has \texttt{x} number of elements, then the function will get the
\texttt{text} entries of each of those elements. Your function should
return the conversation, prepending each field with either ' Person 1: '
if `x' is even or ' Person 2: ' if `x' is odd. You can use the Python
modulus operator `\%' to help select the even/odd entries. Important
note: Do not print a newline character (i.e.~\texttt{\textbackslash{}n})
when generating the string. For example, in the code cell above, your
function should output something like:

\begin{verbatim}
 Person 1: I would like a taxi from Saint John's college to Pizza Hut Fen Ditton. Person 2: What time do you want to leave and what time do you want to arrive by?
\end{verbatim}

and \textbf{not}:

\begin{verbatim}
 Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.
 Person 2:  What time do you want to leave and what time do you want to arrive by?
\end{verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C1}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: get\PYZus{}conversation}
\PY{k}{def} \PY{n+nf}{get\PYZus{}conversation}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{data\PYZus{}db}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        file (string): filename of the dialogue file saved as json}
\PY{l+s+sd}{        data\PYZus{}db (dict): dialogue database}
\PY{l+s+sd}{    }
\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        string: A string containing the \PYZsq{}text\PYZsq{} fields of  data[file][\PYZsq{}log\PYZsq{}][x]}
\PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
    
    \PY{c+c1}{\PYZsh{} initialize empty string}
    \PY{n}{result} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}
    
    \PY{c+c1}{\PYZsh{} get length of file\PYZsq{}s log list}
    \PY{n}{len\PYZus{}msg\PYZus{}log} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{data\PYZus{}db}\PY{p}{[}\PY{n}{file}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} set the delimiter strings}
    \PY{n}{delimiter\PYZus{}1} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 1: }\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{delimiter\PYZus{}2} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 2: }\PY{l+s+s1}{\PYZsq{}}
    
    \PY{c+c1}{\PYZsh{} loop over the file\PYZsq{}s log list}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{len\PYZus{}msg\PYZus{}log}\PY{p}{)}\PY{p}{:}
        
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
        \PY{c+c1}{\PYZsh{} get i\PYZsq{}th element of file log list}
        \PY{n}{cur\PYZus{}log} \PY{o}{=} \PY{n}{data\PYZus{}db}\PY{p}{[}\PY{n}{file}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} check if i is even}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{l+m+mi}{2} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}                   
            \PY{c+c1}{\PYZsh{} append the 1st delimiter string}
            \PY{n}{result} \PY{o}{+}\PY{o}{=} \PY{n}{delimiter\PYZus{}1}
        \PY{k}{else}\PY{p}{:} 
            \PY{c+c1}{\PYZsh{} append the 2nd delimiter string}
            \PY{n}{result} \PY{o}{+}\PY{o}{=} \PY{n}{delimiter\PYZus{}2}
        
        \PY{c+c1}{\PYZsh{} append the message text from the log}
        \PY{n}{result} \PY{o}{+}\PY{o}{=} \PY{n}{cur\PYZus{}log}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}

    \PY{k}{return} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{k+kn}{import} \PY{n+nn}{w4\PYZus{}unittest}
\PY{n}{w4\PYZus{}unittest}\PY{o}{.}\PY{n}{test\PYZus{}get\PYZus{}conversation}\PY{p}{(}\PY{n}{get\PYZus{}conversation}\PY{p}{)}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-green-intense}{ All tests passed}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{file} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG01856.json}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{conversation} \PY{o}{=} \PY{n}{get\PYZus{}conversation}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{)}

\PY{c+c1}{\PYZsh{} print raw output}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conversation}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
 Person 1: am looking for a place to to stay that has cheap price range it
should be in a type of hotel Person 2: Okay, do you have a specific area you
want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i
need parking Person 2: I found 1 cheap hotel for you that includes parking. Do
you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on
tuesday. Person 2: I am sorry but I wasn't able to book that for you for
Tuesday. Is there another day you would like to stay or perhaps a shorter stay?
Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No,
that will be all. Good bye. Person 2: Thank you for using our services.
    \end{Verbatim}

    \textbf{Expected Result:}

\begin{verbatim}
Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.
\end{verbatim}

    We can have a utility pretty print function just so we can visually
follow the conversation more easily.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{print\PYZus{}conversation}\PY{p}{(}\PY{n}{conversation}\PY{p}{)}\PY{p}{:}
    
    \PY{n}{delimiter\PYZus{}1} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 1: }\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{delimiter\PYZus{}2} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 2: }\PY{l+s+s1}{\PYZsq{}}
    
    \PY{n}{split\PYZus{}list\PYZus{}d1} \PY{o}{=} \PY{n}{conversation}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{delimiter\PYZus{}1}\PY{p}{)}
    
    \PY{k}{for} \PY{n}{sublist} \PY{o+ow}{in} \PY{n}{split\PYZus{}list\PYZus{}d1}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{:}
        \PY{n}{split\PYZus{}list\PYZus{}d2} \PY{o}{=} \PY{n}{sublist}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{delimiter\PYZus{}2}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{colored}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 1: }\PY{l+s+si}{\PYZob{}}\PY{n}{split\PYZus{}list\PYZus{}d2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        
        \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{split\PYZus{}list\PYZus{}d2}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{1}\PY{p}{:}
            \PY{n+nb}{print}\PY{p}{(}\PY{n}{colored}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 2: }\PY{l+s+si}{\PYZob{}}\PY{n}{split\PYZus{}list\PYZus{}d2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}

            
\PY{n}{print\PYZus{}conversation}\PY{p}{(}\PY{n}{conversation}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-red}{Person 1: am looking for a place to to stay that has cheap price range it
should be in a type of hotel }
\textcolor{ansi-green}{Person 2: Okay, do you have a specific area you want to stay in? }
\textcolor{ansi-red}{Person 1: no, i just need to make sure it's cheap. oh, and i need parking
}
\textcolor{ansi-green}{Person 2: I found 1 cheap hotel for you that includes parking. Do you like
me to book it? }
\textcolor{ansi-red}{Person 1: Yes, please. 6 people 3 nights starting on tuesday. }
\textcolor{ansi-green}{Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is
there another day you would like to stay or perhaps a shorter stay? }
\textcolor{ansi-red}{Person 1: how about only 2 nights. }
\textcolor{ansi-green}{Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? }
\textcolor{ansi-red}{Person 1: No, that will be all. Good bye. }
\textcolor{ansi-green}{Person 2: Thank you for using our services.}
    \end{Verbatim}

    For this assignment, we will just use the outputs of the calls to
\texttt{get\_conversation} to train the model. But just to expound,
there are also other information in the MultiWoz dataset that can be
useful in other contexts. Each element of the log list has more
information about it. For example, above, if you were to look at the
other fields for the following, ``am looking for a place to stay that
has cheap price range it should be in a type of hotel'', you will get
the following.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SNG01856.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\{'text': 'am looking for a place to to stay that has cheap price range it should
be in a type of hotel',
 'metadata': \{\},
 'dialog\_act': \{'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]\},
 'span\_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],
  ['Hotel-Inform', 'Price', 'cheap', 10, 10]]\}
\end{Verbatim}
\end{tcolorbox}
        
    The dataset also comes with hotel, hospital, taxi, train, police, and
restaurant databases. For example, in case you need to call a doctor, or
a hotel, or a taxi, this will allow you to automate the entire
conversation. Take a look at the files accompanying the data set.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this is an example of the attractions file}
\PY{n}{attraction\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/attraction\PYZus{}db.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{attractions} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{attraction\PYZus{}file}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{attractions}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east',
'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name':
'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088',
'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'\}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this is an example of the hospital file}
\PY{n}{hospital\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/hospital\PYZus{}db.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{hospitals} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{hospital\PYZus{}file}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{hospitals}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} feel free to index into other indices}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'department': 'neurosciences critical care unit', 'id': 0, 'phone':
'01223216297'\}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this is an example of the hotel file}
\PY{n}{hotel\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/hotel\PYZus{}db.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{hotels} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{hotel\PYZus{}file}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{hotels}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} feel free to index into other indices}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking':
'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest
house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': \{'double': '70',
'family': '90', 'single': '50'\}, 'pricerange': 'moderate', 'stars': '4',
'takesbookings': 'yes', 'type': 'guesthouse'\}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this is an example of the police file}
\PY{n}{police\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/police\PYZus{}db.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{police} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{police\PYZus{}file}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{police}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} feel free to index into other indices}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0,
'phone': '01223358966'\}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this is an example of a restuarant file}
\PY{n}{restaurant\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/restaurant\PYZus{}db.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{restaurants} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{restaurant\PYZus{}file}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{restaurants}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} feel free to index into other indices}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian',
'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants
nationwide offering convenience pizzas pasta and salads to eat in or take away',
'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone':
'01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type':
'restaurant'\}
    \end{Verbatim}

    For more information about the multiwoz 2.1 data set, please run the
cell below to read the \texttt{ReadMe.txt} file. Feel free to open any
other file to explore it.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/README}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{file}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#  Copyright Cambridge Dialogue Systems Group, 2018 \#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

Dataset contains the following files:
1. data.json: the woz dialogue dataset, which contains the conversation  users
and wizards, as well as a set of coarse labels for each user turn. This file
contains both system and user dialogue acts annotated at the turn level. Files
with multi-domain dialogues have "MUL" in their names. Single domain dialogues
have either "SNG" or "WOZ" in their names.
2. restaurant\_db.json: the Cambridge restaurant database file, containing
restaurants in the Cambridge UK area and a set of attributes.
3. attraction\_db.json: the Cambridge attraction database file, contining
attractions in the Cambridge UK area and a set of attributes.
4. hotel\_db.json: the Cambridge hotel database file, containing hotels in the
Cambridge UK area and a set of attributes.
5. train\_db.json: the Cambridge train (with artificial connections) database
file, containing trains in the Cambridge UK area and a set of attributes.
6. hospital\_db.json: the Cambridge hospital database file, contatining
information about departments.
7. police\_db.json: the Cambridge police station information.
8. taxi\_db.json: slot-value list for taxi domain.
9. valListFile.txt: list of dialogues for validation.
10. testListFile.txt: list of dialogues for testing.
11. system\_acts.json:
  There are 6 domains ('Booking', 'Restaurant', 'Hotel', 'Attraction', 'Taxi',
'Train') and 1 dummy domain ('general').
  A domain-dependent dialogue act is defined as a domain token followed by a
domain-independent dialogue act, e.g. 'Hotel-inform' means it is an 'inform' act
in the Hotel domain.
  Dialogue acts which cannot take slots, e.g., 'good bye', are defined under the
'general' domain.
  A slot-value pair defined as a list with two elements. The first element is
slot token and the second one is its value.
  If a dialogue act takes no slots, e.g., dialogue act 'offer booking' for an
utterance 'would you like to take a reservation?', its slot-value pair is
['none', 'none']
  There are four types of values:
  1) If a slot takes a binary value, e.g., 'has Internet' or 'has park', the
value is either 'yes' or 'no'.
  2) If a slot is under the act 'request', e.g., 'request' about 'area', the
value is expressed as '?'.
  3) The value that appears in the utterance e.g., the name of a restaurant.
  4) If for some reason the turn does not have an annotation then it is labeled
as "No Annotation."
12. ontology.json: Data-based ontology containing all the values for the
different slots in the domains.
13. slot\_descriptions.json: A collection of human-written slot descriptions for
each slot in the dataset. Each slot has at least two descriptions.
14. tokenization.md: A description of the tokenization preprocessing we had to
perform to maintain consistency between the dialogue act annotations of DSTC 8
Track 1 and the existing MultiWOZ 2.0 data.

    \end{Verbatim}

    As you can see, there are many other aspects of the MultiWoz dataset.
Nonetheless, you'll see that even with just the conversations, your
model will still be able to generate useful responses. This concludes
our exploration of the dataset. In the next section, we will do some
preprocessing before we feed it into our model for training.

    \# Part 2: Processing the data for Reformer inputs

You will now use the \texttt{get\_conversation()} function to process
the data. The Reformer expects inputs of this form:

\textbf{Person 1: Why am I so happy? Person 2: Because you are learning
NLP Person 1: \ldots{} Person 2: \ldots{}}*

And the conversation keeps going with some text. As you can see `Person
1' and `Person 2' act as delimiters so the model automatically
recognizes the person and who is talking. It can then come up with the
corresponding text responses for each person. Let's proceed to process
the text in this fashion for the Reformer. First, let's grab all the
conversation strings from all dialogue files and put them in a list.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} the keys are the file names}
\PY{n}{all\PYZus{}files} \PY{o}{=} \PY{n}{DIALOGUE\PYZus{}DB}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} initialize empty list}
\PY{n}{untokenized\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{c+c1}{\PYZsh{} loop over all files}
\PY{k}{for} \PY{n}{file} \PY{o+ow}{in} \PY{n}{all\PYZus{}files}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} this is the graded function you coded}
    \PY{c+c1}{\PYZsh{} returns a string delimited by Person 1 and Person 2}
    \PY{n}{result} \PY{o}{=} \PY{n}{get\PYZus{}conversation}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{DIALOGUE\PYZus{}DB}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} append to the list}
    \PY{n}{untokenized\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{result}\PY{p}{)}

\PY{c+c1}{\PYZsh{} print the first element to check if it\PYZsq{}s the same as the one we got before}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{untokenized\PYZus{}data}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
 Person 1: am looking for a place to to stay that has cheap price range it
should be in a type of hotel Person 2: Okay, do you have a specific area you
want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i
need parking Person 2: I found 1 cheap hotel for you that includes parking. Do
you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on
tuesday. Person 2: I am sorry but I wasn't able to book that for you for
Tuesday. Is there another day you would like to stay or perhaps a shorter stay?
Person 1: how about only 2 nights. Person 2: Booking was successful.
Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No,
that will be all. Good bye. Person 2: Thank you for using our services.
    \end{Verbatim}

    Now let us split the list to a train and eval dataset.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} shuffle the list we generated above}
\PY{n}{random}\PY{o}{.}\PY{n}{shuffle}\PY{p}{(}\PY{n}{untokenized\PYZus{}data}\PY{p}{)}

\PY{c+c1}{\PYZsh{} define a cutoff (5\PYZpc{} of the total length for this assignment)}
\PY{c+c1}{\PYZsh{} convert to int because we will use it as a list index}
\PY{n}{cut\PYZus{}off} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{untokenized\PYZus{}data}\PY{p}{)} \PY{o}{*} \PY{o}{.}\PY{l+m+mi}{05}\PY{p}{)}

\PY{c+c1}{\PYZsh{} slice the list. the last elements after the cut\PYZus{}off value will be the eval set. the rest is for training. }
\PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{eval\PYZus{}data} \PY{o}{=} \PY{n}{untokenized\PYZus{}data}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{n}{cut\PYZus{}off}\PY{p}{]}\PY{p}{,} \PY{n}{untokenized\PYZus{}data}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{n}{cut\PYZus{}off}\PY{p}{:}\PY{p}{]}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of conversations in the data set: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{untokenized\PYZus{}data}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of conversations in train set: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of conversations in eval set: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{eval\PYZus{}data}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
number of conversations in the data set: 10438
number of conversations in train set: 9917
number of conversations in eval set: 521
    \end{Verbatim}

    \#\# 2.1 Tokenizing, batching with bucketing We can now proceed in
generating tokenized batches of our data. Let's first define a utility
generator function to yield elements from our data sets:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{stream}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} loop over the entire data}
    \PY{k}{while} \PY{k+kc}{True}\PY{p}{:}
        \PY{c+c1}{\PYZsh{} get a random element}
        \PY{n}{d} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} yield a tuple pair of identical values }
        \PY{c+c1}{\PYZsh{} (i.e. our inputs to the model will also be our targets during training)}
        \PY{k}{yield} \PY{p}{(}\PY{n}{d}\PY{p}{,} \PY{n}{d}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Now let's define our data pipeline for tokenizing and batching our data.
As in the previous assignments, we will bucket by length and also have
an upper bound on the token length.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} trax allows us to use combinators to generate our data pipeline}
\PY{n}{data\PYZus{}pipeline} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{Serial}\PY{p}{(}
    \PY{c+c1}{\PYZsh{} randomize the stream}
    \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{Shuffle}\PY{p}{(}\PY{p}{)}\PY{p}{,}
    
    \PY{c+c1}{\PYZsh{} tokenize the data}
    \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{Tokenize}\PY{p}{(}\PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,}
                       \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{)}\PY{p}{,}
    
    \PY{c+c1}{\PYZsh{} filter too long sequences}
    \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{FilterByLength}\PY{p}{(}\PY{l+m+mi}{2048}\PY{p}{)}\PY{p}{,}
    
    \PY{c+c1}{\PYZsh{} bucket by length}
    \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{BucketByLength}\PY{p}{(}\PY{n}{boundaries}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{,}  \PY{l+m+mi}{512}\PY{p}{,} \PY{l+m+mi}{1024}\PY{p}{]}\PY{p}{,}
                             \PY{n}{batch\PYZus{}sizes}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}    \PY{l+m+mi}{8}\PY{p}{,}    \PY{l+m+mi}{4}\PY{p}{,}   \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
    
    \PY{c+c1}{\PYZsh{} add loss weights but do not add it to the padding tokens (i.e. 0)}
    \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{AddLossWeights}\PY{p}{(}\PY{n}{id\PYZus{}to\PYZus{}mask}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} apply the data pipeline to our train and eval sets}
\PY{n}{train\PYZus{}stream} \PY{o}{=} \PY{n}{data\PYZus{}pipeline}\PY{p}{(}\PY{n}{stream}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}\PY{p}{)}
\PY{n}{eval\PYZus{}stream} \PY{o}{=} \PY{n}{data\PYZus{}pipeline}\PY{p}{(}\PY{n}{stream}\PY{p}{(}\PY{n}{eval\PYZus{}data}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Peek into the train stream.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} the stream generators will yield (input, target, weights). let\PYZsq{}s just grab the input for inspection}
\PY{n}{inp}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n+nb}{next}\PY{p}{(}\PY{n}{train\PYZus{}stream}\PY{p}{)}

\PY{c+c1}{\PYZsh{} print the shape. format is (batch size, token length)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{input shape: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{inp}\PY{o}{.}\PY{n}{shape}\PY{p}{)}

\PY{c+c1}{\PYZsh{} detokenize the first element}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{detokenize}\PY{p}{(}\PY{n}{inp}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
input shape:  (4, 512)
 Person 1: Can you help me find a 4 star expensive hotel? Person 2: The
University Arms Hotel fits that description. Would you like me to book it for
you? Person 1: Is that a guesthouse? Person 2: No sorry that is a hotel. Person
1: Is there a guesthouse available? Person 2: Unfortunately, there are no
guesthouses that fit that description.  Person 1: I would be interested in a
guesthouse in the cheap price range if that is available.  Will you check for
me? Person 2: There are 7 available that match what you're looking for, do you
have any preference for what area you want to stay in? Person 1: I need free
internet and I need their postcode. Person 2: There is the Alexander Bed and
Breakfast which has internet. It is located in cb12de postal code. Person 1: I
also need a restaurant with south African food in the centre.  Person 2: I am
sorry there are no restaurants that match that description. Would you like to
search for something else? Person 1: How about a restaurant that serves Italian
food, do you have one that you would recommend? Person 2: How about the zizzi
cambridge in the centre? Person 1: Sure, I would like to book a reservation for
that. But first, could you tell me what area the Alexander Bed and Breakfast is
in? Person 2: It is in the centre area.  Is there anything else that I can do
for you? Person 1: Yes, I still need to book a reservation for 8 people at Zizzi
Cambridge.  Person 2: What day and time would you like to go to zizzi cambridge?
Person 1: Friday, 17:45.  Person 2: You are booked.  Your table will be reserved
for 15 minutes with reference \#VNRRC76K. Person 1: Thank you. That's all I
needed. Have a nice day! Person 2: You're welcome! Thank you for contacting us,
have a great day!
    \end{Verbatim}

    \# Part 3: Reversible layers

When running large deep models, you will often run out of memory as each
layer allocates memory to store activations for use in backpropagation.
To save this resource, you need to be able to recompute these
activations during the backward pass without storing them during the
forward pass. Take a look first at the leftmost diagram below.

\begin{description}
\tightlist
\item[This is how the residual networks are implemented in the standard
Transformer. It follows that, given \texttt{F()} is Attention and
\texttt{G()} is Feed-forward(FF).]
\end{description}

\begin{align}  
\mathrm{y}_\mathrm{a} &= \mathrm{x} + \mathrm{F}\left(\mathrm{x}\right)\tag{1} \\
\mathrm{y}_{b}&=\mathrm{y}_{a}+\mathrm{G}\left(\mathrm{y}_{a}\right)\tag{2}\\
\end{align}

As you can see, it requires that \(\mathrm{x}\) and \(\mathrm{y}_{a}\)
be saved so it can be used during backpropagation. We want to avoid this
to conserve memory and this is where reversible residual connections
come in. They are shown in the middle and rightmost diagrams above. The
key idea is that we will start with two copies of the input to the model
and at each layer we will only update one of them. The activations that
we \emph{don't} update are the ones that will be used to compute the
residuals.

Now in this reversible set up you get the following instead:

\begin{align}  
\mathrm{y}_{1}&=\mathrm{x}_{1}+\mathrm{F}\left(\mathrm{x}_{2}\right)\tag{3}\\
\mathrm{y}_{2}&=\mathrm{x}_{2}+\mathrm{G}\left(\mathrm{y}_{1}\right)\tag{4}\\
\end{align} To recover \(\mathrm{(x_1,x_2)}\) from
\(\mathrm{(y_1, y_2)}\)

\begin{align}  
\mathrm{x}_{2}&=\mathrm{y}_{2}-\mathrm{G}\left(\mathrm{y}_{1}\right)\tag{5}\\
\mathrm{x}_{1}&=\mathrm{y}_{1}-\mathrm{F}\left(\mathrm{x}_{2}\right)\tag{6}\\
\end{align}

With this configuration, we're now able to run the network fully in
reverse. You'll notice that during the backward pass, \(\mathrm{x2}\)
and \(\mathrm{x1}\) can be recomputed based solely on the values of
\(\mathrm{y2}\) and \(\mathrm{y1}\). No need to save it during the
forward pass.

\#\#\# Exercise 02 \textbf{Instructions:} You will implement the
\texttt{reversible\_layer\_forward} function using equations 3 and 4
above. This function takes in the input vector \texttt{x} and the
functions \texttt{f} and \texttt{g} and returns the concatenation of
\(y_1 and y_2\). For this exercise, we will be splitting \texttt{x}
before going through the reversible residual steps\(\mathrm{^1}\). We
can then use those two vectors for the
\texttt{reversible\_layer\_reverse} function. Utilize
\texttt{np.concatenate()} to form the output being careful to match the
axis of the \texttt{np.split()}.

\(\mathrm{^1}\)\emph{Take note that this is just for demonstrating the
concept in this exercise and there are other ways of processing the
input. As you'll see in the Reformer architecture later, the initial
input (i.e.~\texttt{x}) can instead be duplicated instead of split.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C2}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: reversible\PYZus{}layer\PYZus{}forward}
\PY{k}{def} \PY{n+nf}{reversible\PYZus{}layer\PYZus{}forward}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args: }
\PY{l+s+sd}{        x (np.array): an input vector or matrix}
\PY{l+s+sd}{        f (function): a function which operates on a vector/matrix}
\PY{l+s+sd}{        g (function): a function which operates on a vector/matrix}
\PY{l+s+sd}{    Returns: }
\PY{l+s+sd}{        y (np.array): an output vector or matrix whose form is determined by \PYZsq{}x\PYZsq{}, f and g}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{c+c1}{\PYZsh{} split the input vector into two (* along the last axis because it is the depth dimension)}
    \PY{n}{x1}\PY{p}{,} \PY{n}{x2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} 
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} get y1 using equation 3}
    \PY{n}{y1} \PY{o}{=} \PY{n}{x1} \PY{o}{+} \PY{n}{f}\PY{p}{(}\PY{n}{x2}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} get y2 using equation 4}
    \PY{n}{y2} \PY{o}{=} \PY{n}{x2} \PY{o}{+} \PY{n}{g}\PY{p}{(}\PY{n}{y1}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} concatenate y1 and y2 along the depth dimension. be sure output is of type np.ndarray}
    \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{[}\PY{n}{y1}\PY{p}{,} \PY{n}{y2}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{} }
    \PY{k}{return} \PY{n}{y}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{n}{w4\PYZus{}unittest}\PY{o}{.}\PY{n}{test\PYZus{}reversible\PYZus{}layer\PYZus{}forward}\PY{p}{(}\PY{n}{reversible\PYZus{}layer\PYZus{}forward}\PY{p}{)}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-green-intense}{ All tests passed}
    \end{Verbatim}

    \#\#\# Exercise 03

You will now implement the \texttt{reversible\_layer\_reverse} function
which is possible because at every time step you have \(x_1\) and
\(x_2\) and \(y_2\) and \(y_1\), along with the function \texttt{f}, and
\texttt{g}. Where \texttt{f} is the attention and \texttt{g} is the
feedforward. This allows you to compute equations 5 and 6.

\textbf{Instructions:} Implement the
\texttt{reversible\_layer\_reverse}. Your function takes in the output
vector from \texttt{reversible\_layer\_forward} and functions f and g.
Using equations 5 and 6 above, it computes the inputs to the layer,
\(x_1\) and \(x_2\). The output, x, is the concatenation of
\(x_1, x_2\). Utilize \texttt{np.concatenate()} to form the output being
careful to match the axis of the \texttt{np.split()}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C3}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: reversible\PYZus{}layer\PYZus{}reverse}
\PY{k}{def} \PY{n+nf}{reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args: }
\PY{l+s+sd}{        y (np.array): an input vector or matrix}
\PY{l+s+sd}{        f (function): a function which operates on a vector/matrix of the form of \PYZsq{}y\PYZsq{}}
\PY{l+s+sd}{        g (function): a function which operates on a vector/matrix of the form of \PYZsq{}y\PYZsq{}}
\PY{l+s+sd}{    Returns: }
\PY{l+s+sd}{        y (np.array): an output vector or matrix whose form is determined by \PYZsq{}y\PYZsq{}, f and g}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{c+c1}{\PYZsh{} split the input vector into two (* along the last axis because it is the depth dimension)}
    \PY{n}{y1}\PY{p}{,} \PY{n}{y2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} compute x2 using equation 5}
    \PY{n}{x2} \PY{o}{=} \PY{n}{y2} \PY{o}{\PYZhy{}} \PY{n}{g}\PY{p}{(}\PY{n}{y1}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} compute x1 using equation 6}
    \PY{n}{x1} \PY{o}{=} \PY{n}{y1} \PY{o}{\PYZhy{}} \PY{n}{f}\PY{p}{(}\PY{n}{x2}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} concatenate x1 and x2 along the depth dimension}
    \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{[}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{} }
    \PY{k}{return} \PY{n}{x}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{n}{w4\PYZus{}unittest}\PY{o}{.}\PY{n}{test\PYZus{}reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{(}\PY{n}{reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{)}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-green-intense}{ All tests passed}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNIT TEST COMMENT: assert at the end can be used in grading as well}
\PY{n}{f} \PY{o}{=} \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x} \PY{o}{+} \PY{l+m+mi}{2}
\PY{n}{g} \PY{o}{=} \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x} \PY{o}{*} \PY{l+m+mi}{3}
\PY{n}{input\PYZus{}vector} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,}\PY{p}{)}\PY{p}{)}

\PY{n}{output\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}forward}\PY{p}{(}\PY{n}{input\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}
\PY{n}{reversed\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{(}\PY{n}{output\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}

\PY{k}{assert} \PY{n}{np}\PY{o}{.}\PY{n}{allclose}\PY{p}{(}\PY{n}{reversed\PYZus{}vector}\PY{p}{,} \PY{n}{input\PYZus{}vector}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \#\# 3.1 Reversible layers and randomness

This is why we were learning about fastmath's random functions and keys
in Course 3 Week 1. Utilizing the same key,
\texttt{trax.fastmath.random.uniform()} will return the same values.
This is required for the backward pass to return the correct layer
inputs when random noise is introduced in the layer.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Layers like dropout have noise, so let\PYZsq{}s simulate it here:}
\PY{n}{f} \PY{o}{=} \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x} \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}

\PY{c+c1}{\PYZsh{} See that the above doesn\PYZsq{}t work any more:}
\PY{n}{output\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}forward}\PY{p}{(}\PY{n}{input\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}
\PY{n}{reversed\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{(}\PY{n}{output\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}

\PY{k}{assert} \PY{o+ow}{not} \PY{n}{np}\PY{o}{.}\PY{n}{allclose}\PY{p}{(}\PY{n}{reversed\PYZus{}vector}\PY{p}{,} \PY{n}{input\PYZus{}vector}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Fails!!}

\PY{c+c1}{\PYZsh{} It failed because the noise when reversing used a different random seed.}

\PY{n}{random\PYZus{}seed} \PY{o}{=} \PY{l+m+mi}{27686}
\PY{n}{rng} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{fastmath}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{get\PYZus{}prng}\PY{p}{(}\PY{n}{random\PYZus{}seed}\PY{p}{)}
\PY{n}{f} \PY{o}{=} \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x} \PY{o}{+} \PY{n}{trax}\PY{o}{.}\PY{n}{fastmath}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{n}{key}\PY{o}{=}\PY{n}{rng}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}

\PY{c+c1}{\PYZsh{} See that it works now as the same rng is used on forward and reverse.}
\PY{n}{output\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}forward}\PY{p}{(}\PY{n}{input\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}
\PY{n}{reversed\PYZus{}vector} \PY{o}{=} \PY{n}{reversible\PYZus{}layer\PYZus{}reverse}\PY{p}{(}\PY{n}{output\PYZus{}vector}\PY{p}{,} \PY{n}{f}\PY{p}{,} \PY{n}{g}\PY{p}{)}

\PY{k}{assert} \PY{n}{np}\PY{o}{.}\PY{n}{allclose}\PY{p}{(}\PY{n}{reversed\PYZus{}vector}\PY{p}{,} \PY{n}{input\PYZus{}vector}\PY{p}{,}  \PY{n}{atol}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}07}\PY{p}{)} 
\end{Verbatim}
\end{tcolorbox}

    \# Part 4: ReformerLM Training

You will now proceed to training your model. Since you have already know
the two main components that differentiates it from the standard
Transformer, LSH in Course 1 and reversible layers above, you can just
use the pre-built model already implemented in Trax. It will have this
architecture:

Similar to the Transformer you learned earlier, you want to apply an
attention and feed forward layer to your inputs. For the Reformer, we
improve the memory efficiency by using \textbf{reversible decoder
blocks} and you can picture its implementation in Trax like below:

You can see that it takes the initial inputs \texttt{x1} and \texttt{x2}
and does the first equation of the reversible networks you learned in
Part 3. As you've also learned, the reversible residual has two
equations for the forward-pass so doing just one of them will just
constitute half of the reversible decoder block. Before doing the second
equation (i.e.~second half of the reversible residual), it first needs
to swap the elements to take into account the stack semantics in Trax.
It simply puts \texttt{x2} on top of the stack so it can be fed to the
add block of the half-residual layer. It then swaps the two outputs
again so it can be fed to the next layer of the network. All of these
arrives at the two equations in Part 3 and it can be used to recompute
the activations during the backward pass.

These are already implemented for you in Trax and in the following
exercise, you'll get to practice how to call them to build your network.

    \#\#\# Exercise 04 \textbf{Instructions:} Implement a wrapper function
that returns a Reformer Language Model. You can use Trax's
\href{https://trax-ml.readthedocs.io/en/latest/trax.models.html\#trax.models.reformer.reformer.ReformerLM}{ReformerLM}
to do this quickly. It will have the same architecture as shown above.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C4}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION}
\PY{k}{def} \PY{n+nf}{ReformerLM}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{33000}\PY{p}{,} \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{attention\PYZus{}type}\PY{o}{=}\PY{n}{tl}\PY{o}{.}\PY{n}{SelfAttention}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args: }
\PY{l+s+sd}{        vocab\PYZus{}size (int): size of the vocabulary}
\PY{l+s+sd}{        n\PYZus{}layers (int): number of decoder layers}
\PY{l+s+sd}{        mode (string): setting of the model which can be \PYZsq{}train\PYZsq{}, \PYZsq{}eval\PYZsq{}, or \PYZsq{}predict\PYZsq{} }
\PY{l+s+sd}{        attention\PYZus{}type(class): attention class to use }
\PY{l+s+sd}{    Returns: }
\PY{l+s+sd}{        model (ReformerLM): a reformer language model implemented in Trax}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}    
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    \PY{c+c1}{\PYZsh{} initialize an instance of Trax\PYZsq{}s ReformerLM class}
    \PY{n}{model} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{models}\PY{o}{.}\PY{n}{reformer}\PY{o}{.}\PY{n}{ReformerLM}\PY{p}{(} 
        \PY{c+c1}{\PYZsh{} set vocab size}
        \PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{n}{vocab\PYZus{}size}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} set number of layers}
        \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{n}{n\PYZus{}layers}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} set mode}
        \PY{n}{mode}\PY{o}{=}\PY{n}{mode}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} set attention type}
        \PY{n}{attention\PYZus{}type}\PY{o}{=}\PY{n}{attention\PYZus{}type}
    \PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    \PY{k}{return} \PY{n}{model}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{34}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} display the model}
\PY{n}{temp\PYZus{}model} \PY{o}{=} \PY{n}{ReformerLM}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{temp\PYZus{}model}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} free memory}
\PY{k}{del} \PY{n}{temp\PYZus{}model} 
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Serial[
  ShiftRight(1)
  Embedding\_train\_512
  Dropout
  PositionalEncoding
  Dup\_out2
  ReversibleSerial\_in2\_out2[
    ReversibleHalfResidualV2\_in2\_out2[
      Serial[
        LayerNorm
      ]
      SelfAttention
    ]
    ReversibleSwap\_in2\_out2
    ReversibleHalfResidualV2\_in2\_out2[
      Serial[
        LayerNorm
        Dense\_2048
        Dropout
        FastGelu
        Dense\_512
        Dropout
      ]
    ]
    ReversibleSwap\_in2\_out2
    ReversibleHalfResidualV2\_in2\_out2[
      Serial[
        LayerNorm
      ]
      SelfAttention
    ]
    ReversibleSwap\_in2\_out2
    ReversibleHalfResidualV2\_in2\_out2[
      Serial[
        LayerNorm
        Dense\_2048
        Dropout
        FastGelu
        Dense\_512
        Dropout
      ]
    ]
    ReversibleSwap\_in2\_out2
  ]
  Concatenate\_in2
  LayerNorm
  Dropout
  Dense\_train
  LogSoftmax
]
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{n}{w4\PYZus{}unittest}\PY{o}{.}\PY{n}{test\PYZus{}ReformerLM}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{)}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-green-intense}{ All tests passed}
    \end{Verbatim}

    \#\#\# Exercise 05 You will now write a function that takes in your
model and trains it.

\textbf{Instructions:} Implement the \texttt{training\_loop} below to
train the neural network above. Here is a list of things you should do:

\begin{itemize}
\tightlist
\item
  Create \texttt{TrainTask} and \texttt{EvalTask}
\item
  Create the training loop \texttt{trax.supervised.training.Loop}
\item
  Pass in the following depending to train\_task :

  \begin{itemize}
  \tightlist
  \item
    \texttt{labeled\_data=train\_gen}
  \item
    \texttt{loss\_layer=tl.CrossEntropyLoss()}
  \item
    \texttt{optimizer=trax.optimizers.Adam(0.01)}
  \item
    \texttt{lr\_schedule=lr\_schedule}
  \item
    \texttt{n\_steps\_per\_checkpoint=10}
  \end{itemize}
\end{itemize}

You will be using your CrossEntropyLoss loss function with Adam
optimizer. Please read the
\href{https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html?highlight=adam\#trax.optimizers.adam.Adam}{trax}
documentation to get a full understanding.

\begin{itemize}
\tightlist
\item
  Pass in the following to eval\_task:

  \begin{itemize}
  \tightlist
  \item
    \texttt{labeled\_data=eval\_gen}
  \item
    \texttt{metrics={[}tl.CrossEntropyLoss(),\ tl.Accuracy(){]}}
  \end{itemize}
\end{itemize}

This function should return a \texttt{training.Loop} object. To read
more about this check the
\href{https://trax-ml.readthedocs.io/en/latest/trax.supervised.html?highlight=loop\#trax.supervised.training.Loop}{docs}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C5}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION: train\PYZus{}model}
\PY{k}{def} \PY{n+nf}{training\PYZus{}loop}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{train\PYZus{}gen}\PY{p}{,} \PY{n}{eval\PYZus{}gen}\PY{p}{,} \PY{n}{output\PYZus{}dir} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./model/}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        ReformerLM:  the Reformer language model you are building}
\PY{l+s+sd}{        train\PYZus{}gen (generator): train data generator.}
\PY{l+s+sd}{        eval\PYZus{}gen (generator): Validation generator. }
\PY{l+s+sd}{        output\PYZus{}dir (string): Path to save the model output. Defaults to \PYZsq{}./model/\PYZsq{}.}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        trax.supervised.training.Loop: Training loop for the model.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}

    \PY{c+c1}{\PYZsh{} use the warmup\PYZus{}and\PYZus{}rsqrt\PYZus{}decay learning rate schedule}
    \PY{n}{lr\PYZus{}schedule} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{lr}\PY{o}{.}\PY{n}{warmup\PYZus{}and\PYZus{}rsqrt\PYZus{}decay}\PY{p}{(}
        \PY{n}{n\PYZus{}warmup\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{max\PYZus{}value}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} define the train task}
    \PY{n}{train\PYZus{}task} \PY{o}{=} \PY{n}{training}\PY{o}{.}\PY{n}{TrainTask}\PY{p}{(}            
        \PY{c+c1}{\PYZsh{} labeled data}
        \PY{n}{labeled\PYZus{}data}\PY{o}{=}\PY{n}{train\PYZus{}gen}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} loss layer}
        \PY{n}{loss\PYZus{}layer}\PY{o}{=}\PY{n}{tl}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} optimizer}
        \PY{n}{optimizer}\PY{o}{=}\PY{n}{trax}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} lr\PYZus{}schedule}
        \PY{n}{lr\PYZus{}schedule}\PY{o}{=}\PY{n}{lr\PYZus{}schedule}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} n\PYZus{}steps}
        \PY{n}{n\PYZus{}steps\PYZus{}per\PYZus{}checkpoint}\PY{o}{=}\PY{l+m+mi}{10}
    \PY{p}{)}

    \PY{c+c1}{\PYZsh{} define the eval task}
    \PY{n}{eval\PYZus{}task} \PY{o}{=} \PY{n}{training}\PY{o}{.}\PY{n}{EvalTask}\PY{p}{(}                      
        \PY{c+c1}{\PYZsh{} labeled data}
        \PY{n}{labeled\PYZus{}data}\PY{o}{=}\PY{n}{eval\PYZus{}gen}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} metrics}
        \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{n}{tl}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{tl}\PY{o}{.}\PY{n}{Accuracy}\PY{p}{(}\PY{p}{)}\PY{p}{]}
    \PY{p}{)}

    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    \PY{n}{loop} \PY{o}{=} \PY{n}{training}\PY{o}{.}\PY{n}{Loop}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{(}\PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,}
                         \PY{n}{train\PYZus{}task}\PY{p}{,}
                         \PY{n}{eval\PYZus{}tasks}\PY{o}{=}\PY{p}{[}\PY{n}{eval\PYZus{}task}\PY{p}{]}\PY{p}{,}
                         \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{)}
    \PY{k}{return} \PY{n}{loop}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNIT TEST COMMENT: Use the train task and eval task for grading train\PYZus{}model}
\PY{n}{test\PYZus{}loop} \PY{o}{=} \PY{n}{training\PYZus{}loop}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{train\PYZus{}stream}\PY{p}{,} \PY{n}{eval\PYZus{}stream}\PY{p}{)}
\PY{n}{train\PYZus{}task} \PY{o}{=} \PY{n}{test\PYZus{}loop}\PY{o}{.}\PY{n}{\PYZus{}task}
\PY{n}{eval\PYZus{}task} \PY{o}{=} \PY{n}{test\PYZus{}loop}\PY{o}{.}\PY{n}{\PYZus{}eval\PYZus{}task}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}task}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{eval\PYZus{}task}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<trax.supervised.training.TrainTask object at 0x7f440d74e0d0>
<trax.supervised.training.EvalTask object at 0x7f43f563dcd0>
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{40}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{n}{w4\PYZus{}unittest}\PY{o}{.}\PY{n}{test\PYZus{}tasks}\PY{p}{(}\PY{n}{train\PYZus{}task}\PY{p}{,} \PY{n}{eval\PYZus{}task}\PY{p}{)}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-green-intense}{ All tests passed}
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} we will now test your function}
\PY{o}{!}rm \PYZhy{}f model/model.pkl.gz
\PY{n}{loop} \PY{o}{=} \PY{n}{training\PYZus{}loop}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{train\PYZus{}stream}\PY{p}{,} \PY{n}{eval\PYZus{}stream}\PY{p}{)}
\PY{n}{loop}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Step      1: Ran 1 train steps in 61.41 secs
Step      1: train CrossEntropyLoss |  10.43317127
Step      1: eval  CrossEntropyLoss |  10.43580055
Step      1: eval          Accuracy |  0.00000000
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        KeyboardInterrupt                         Traceback (most recent call last)

        <ipython-input-41-036bd5875977> in <module>
          2 get\_ipython().system('rm -f model/model.pkl.gz')
          3 loop = training\_loop(ReformerLM, train\_stream, eval\_stream)
    ----> 4 loop.run(10)
    

        /opt/conda/lib/python3.7/site-packages/trax/supervised/training.py in run(self, n\_steps)
        294 
        295         if should\_checkpoint:
    --> 296           self.save\_checkpoint(unr\_weights, unr\_state, unr\_slots)
        297         if should\_eval:
        298           elapsed\_time = time.time() - start\_time


        /opt/conda/lib/python3.7/site-packages/trax/supervised/training.py in save\_checkpoint(self, weights, state, slots)
        563     \}
        564     ckpt\_file = os.path.join(self.\_output\_dir, 'model.pkl.gz')
    --> 565     pickle\_to\_file(d, ckpt\_file, gzip=True)
        566 
        567   def load\_checkpoint(self, directory=None, filename=None):


        /opt/conda/lib/python3.7/site-packages/trax/supervised/training.py in pickle\_to\_file(obj, file\_path, gzip)
        794     else:
        795       with gzip\_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:
    --> 796         pickle.dump(obj, gzipf)
        797   \# Moving a file is much less error-prone than pickling large files.
        798   tf.io.gfile.rename(tmp\_file\_path, file\_path, overwrite=True)


        /opt/conda/lib/python3.7/site-packages/jax/interpreters/xla.py in \_forward\_method(attrname, self, fun, *args)
        962 
        963 def \_forward\_method(attrname, self, fun, *args):
    --> 964   return fun(getattr(self, attrname), *args)
        965 \_forward\_to\_value = partial(\_forward\_method, "\_value")
        966 


        /opt/conda/lib/python3.7/site-packages/jax/interpreters/xla.py in \_value(self)
        997         self.\_npy\_value = lazy.eval\_lexpr(self.\_lazy\_expr, None)
        998       else:
    --> 999         self.\_npy\_value = \_force(self).device\_buffer.to\_py()
       1000       self.\_npy\_value.flags.writeable = False
       1001     return self.\_npy\_value


        KeyboardInterrupt: 

    \end{Verbatim}

    \textbf{Approximate Expected output:}

\begin{verbatim}
Step      1: Ran 1 train steps in 55.73 secs
Step      1: train CrossEntropyLoss |  10.41907787
Step      1: eval  CrossEntropyLoss |  10.41005802
Step      1: eval          Accuracy |  0.00000000

Step     10: Ran 9 train steps in 108.21 secs
Step     10: train CrossEntropyLoss |  10.15449715
Step     10: eval  CrossEntropyLoss |  9.63478279
Step     10: eval          Accuracy |  0.16350447
\end{verbatim}

    \# Part 5: Decode from a pretrained model

We will now proceed on decoding using the model architecture you just
implemented. As in the previous weeks, we will be giving you a
pretrained model so you can observe meaningful output during inference.
You will be using the
\href{https://trax-ml.readthedocs.io/en/latest/trax.supervised.html\#trax.supervised.decoding.autoregressive_sample_stream}{autoregressive\_sample\_stream()}
decoding method from Trax to do fast inference. Let's define a few
parameters to initialize our model.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} define the `predict\PYZus{}mem\PYZus{}len` and `predict\PYZus{}drop\PYZus{}len` of tl.SelfAttention}
\PY{k}{def} \PY{n+nf}{attention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} number of input positions to remember in a cache when doing fast inference. }
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}mem\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}
    \PY{c+c1}{\PYZsh{} number of input elements to drop once the fast inference input cache fills up.}
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}drop\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}
    \PY{c+c1}{\PYZsh{} return the attention layer with the parameters defined above}
    \PY{k}{return} \PY{n}{tl}\PY{o}{.}\PY{n}{SelfAttention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}

\PY{c+c1}{\PYZsh{} define the model using the ReformerLM function you implemented earlier.}
\PY{n}{model} \PY{o}{=} \PY{n}{ReformerLM}\PY{p}{(}
    \PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{33000}\PY{p}{,}
    \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,}
    \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{n}{attention\PYZus{}type}\PY{o}{=}\PY{n}{attention}\PY{p}{,}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.}
\PY{n}{shape11} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{shapes}\PY{o}{.}\PY{n}{ShapeDtype}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{int32}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    We can now initialize our model from a file containing the pretrained
weights. We will save this starting state so we can reset the model
state when we generate a new conversation. This will become clearer in
the \texttt{generate\_dialogue()} function later.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} initialize from file}
\PY{n}{model}\PY{o}{.}\PY{n}{init\PYZus{}from\PYZus{}file}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{chatbot\PYZus{}model1.pkl.gz}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                     \PY{n}{weights\PYZus{}only}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{input\PYZus{}signature}\PY{o}{=}\PY{n}{shape11}\PY{p}{)}

\PY{c+c1}{\PYZsh{} save the starting state}
\PY{n}{STARTING\PYZus{}STATE} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{state}
\end{Verbatim}
\end{tcolorbox}

    Let's define a few utility functions as well to help us tokenize and
detokenize. We can use the
\href{https://trax-ml.readthedocs.io/en/latest/trax.data.html\#trax.data.tf_inputs.tokenize}{tokenize()}
and
\href{https://trax-ml.readthedocs.io/en/latest/trax.data.html\#trax.data.tf_inputs.detokenize}{detokenize()}
from \texttt{trax.data.tf\_inputs} to do this.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{tokenize}\PY{p}{(}\PY{n}{sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n+nb}{list}\PY{p}{(}\PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{tokenize}\PY{p}{(}\PY{n+nb}{iter}\PY{p}{(}\PY{p}{[}\PY{n}{sentence}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{vocab\PYZus{}dir}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

\PY{k}{def} \PY{n+nf}{detokenize}\PY{p}{(}\PY{n}{tokens}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{trax}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{detokenize}\PY{p}{(}\PY{n}{tokens}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{vocab\PYZus{}dir}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    We are now ready to define our decoding function. This will return a
generator that yields that next symbol output by the model. It will be
able to predict the next words by just feeding it a starting sentence.

    \#\#\# Exercise 06 \textbf{Instructions:} Implement the function below
to return a generator that predicts the next word of the conversation.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} UNQ\PYZus{}C6}
\PY{c+c1}{\PYZsh{} GRADED FUNCTION}
\PY{k}{def} \PY{n+nf}{ReformerLM\PYZus{}output\PYZus{}gen}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{p}{,} \PY{n}{temperature}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        ReformerLM:  the Reformer language model you just trained}
\PY{l+s+sd}{        start\PYZus{}sentence (string): starting sentence of the conversation}
\PY{l+s+sd}{        vocab\PYZus{}file (string): vocabulary filename}
\PY{l+s+sd}{        vocab\PYZus{}dir (string): directory of the vocabulary file}
\PY{l+s+sd}{        temperature (float): parameter for sampling ranging from 0.0 to 1.0.}
\PY{l+s+sd}{            0.0: same as argmax, always pick the most probable token}
\PY{l+s+sd}{            1.0: sampling from the distribution (can sometimes say random things)}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        generator: yields the next symbol generated by the model}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} START CODE HERE (REPLACE INSTANCES OF \PYZsq{}None\PYZsq{} WITH YOUR CODE) \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{c+c1}{\PYZsh{} Create input tokens using the the tokenize function}
    \PY{n}{input\PYZus{}tokens} \PY{o}{=} \PY{n}{tokenize}\PY{p}{(}\PY{n}{start\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{vocab\PYZus{}dir}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Add batch dimension to array. Convert from (n,) to (x, n) where }
    \PY{c+c1}{\PYZsh{} x is the batch size. Default is 1. (hint: you can use np.expand\PYZus{}dims() with axis=0)}
    \PY{n}{input\PYZus{}tokens\PYZus{}with\PYZus{}batch} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{input\PYZus{}tokens}\PY{p}{)}\PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{p}{:}\PY{p}{]}
    
    \PY{c+c1}{\PYZsh{} call the autoregressive\PYZus{}sample\PYZus{}stream function from trax}
    \PY{n}{output\PYZus{}gen} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{supervised}\PY{o}{.}\PY{n}{decoding}\PY{o}{.}\PY{n}{autoregressive\PYZus{}sample\PYZus{}stream}\PY{p}{(} 
        \PY{c+c1}{\PYZsh{} model}
        \PY{n}{ReformerLM}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} inputs will be the tokens with batch dimension}
        \PY{n}{inputs}\PY{o}{=}\PY{n}{input\PYZus{}tokens\PYZus{}with\PYZus{}batch}\PY{p}{,}
        \PY{c+c1}{\PYZsh{} temperature}
        \PY{n}{temperature}\PY{o}{=}\PY{n}{temperature}
    \PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} END CODE HERE \PYZsh{}\PYZsh{}\PYZsh{}}
    
    \PY{k}{return} \PY{n}{output\PYZus{}gen}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} BEGIN UNIT TEST}
\PY{k+kn}{import} \PY{n+nn}{pickle}

\PY{n}{WEIGHTS\PYZus{}FROM\PYZus{}FILE} \PY{o}{=} \PY{p}{(}\PY{p}{)}

\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file}\PY{p}{:}
    \PY{n}{WEIGHTS\PYZus{}FROM\PYZus{}FILE} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{file}\PY{p}{)}

\PY{n}{shape11} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{shapes}\PY{o}{.}\PY{n}{ShapeDtype}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{int32}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{attention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}mem\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}drop\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}
    \PY{k}{return} \PY{n}{tl}\PY{o}{.}\PY{n}{SelfAttention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}

\PY{n}{test\PYZus{}model} \PY{o}{=} \PY{n}{ReformerLM}\PY{p}{(}\PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{attention\PYZus{}type}\PY{o}{=}\PY{n}{attention}\PY{p}{)}

\PY{n}{test\PYZus{}output\PYZus{}gen} \PY{o}{=} \PY{n}{ReformerLM\PYZus{}output\PYZus{}gen}\PY{p}{(}\PY{n}{test\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{n}{test\PYZus{}model}\PY{o}{.}\PY{n}{init\PYZus{}weights\PYZus{}and\PYZus{}state}\PY{p}{(}\PY{n}{shape11}\PY{p}{)}

\PY{n}{test\PYZus{}model}\PY{o}{.}\PY{n}{weights} \PY{o}{=} \PY{n}{WEIGHTS\PYZus{}FROM\PYZus{}FILE}

\PY{n}{output} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
    \PY{n}{output}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb}{next}\PY{p}{(}\PY{n}{test\PYZus{}output\PYZus{}gen}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{output}\PY{p}{)}

\PY{c+c1}{\PYZsh{} free memory}
\PY{k}{del} \PY{n}{test\PYZus{}model} 
\PY{k}{del} \PY{n}{WEIGHTS\PYZus{}FROM\PYZus{}FILE}
\PY{k}{del} \PY{n}{test\PYZus{}output\PYZus{}gen}
\PY{c+c1}{\PYZsh{} END UNIT TEST}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[1, 0, 4, 3, 0, 4]
    \end{Verbatim}

    \textbf{\emph{Expected value:}}

{[}1, 0, 4, 3, 0, 4{]}

    Great! Now you will be able to see the model in action. The utility
function below will call the generator you just implemented and will
just format the output to be easier to read.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{shape11} \PY{o}{=} \PY{n}{trax}\PY{o}{.}\PY{n}{shapes}\PY{o}{.}\PY{n}{ShapeDtype}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{int32}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{attention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}mem\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}  \PY{c+c1}{\PYZsh{} max length for predictions}
    \PY{n}{kwargs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}drop\PYZus{}len}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{120}  \PY{c+c1}{\PYZsh{} never drop old stuff}
    \PY{k}{return} \PY{n}{tl}\PY{o}{.}\PY{n}{SelfAttention}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}

\PY{n}{model} \PY{o}{=} \PY{n}{ReformerLM}\PY{p}{(}
    \PY{n}{vocab\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{33000}\PY{p}{,}
    \PY{n}{n\PYZus{}layers}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,}
    \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{n}{attention\PYZus{}type}\PY{o}{=}\PY{n}{attention}\PY{p}{,}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model}\PY{o}{.}\PY{n}{init\PYZus{}from\PYZus{}file}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{chatbot\PYZus{}model1.pkl.gz}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                     \PY{n}{weights\PYZus{}only}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{input\PYZus{}signature}\PY{o}{=}\PY{n}{shape11}\PY{p}{)}

\PY{n}{STARTING\PYZus{}STATE} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{state}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{49}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{generate\PYZus{}dialogue}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{model\PYZus{}state}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{p}{,} \PY{n}{max\PYZus{}len}\PY{p}{,} \PY{n}{temperature}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        ReformerLM:  the Reformer language model you just trained}
\PY{l+s+sd}{        model\PYZus{}state (np.array): initial state of the model before decoding}
\PY{l+s+sd}{        start\PYZus{}sentence (string): starting sentence of the conversation}
\PY{l+s+sd}{        vocab\PYZus{}file (string): vocabulary filename}
\PY{l+s+sd}{        vocab\PYZus{}dir (string): directory of the vocabulary file}
\PY{l+s+sd}{        max\PYZus{}len (int): maximum number of tokens to generate }
\PY{l+s+sd}{        temperature (float): parameter for sampling ranging from 0.0 to 1.0.}
\PY{l+s+sd}{            0.0: same as argmax, always pick the most probable token}
\PY{l+s+sd}{            1.0: sampling from the distribution (can sometimes say random things)}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{        generator: yields the next symbol generated by the model}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}  
    
    \PY{c+c1}{\PYZsh{} define the delimiters we used during training}
    \PY{n}{delimiter\PYZus{}1} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 1: }\PY{l+s+s1}{\PYZsq{}} 
    \PY{n}{delimiter\PYZus{}2} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Person 2: }\PY{l+s+s1}{\PYZsq{}}
    
    \PY{c+c1}{\PYZsh{} initialize detokenized output}
    \PY{n}{sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}
    
    \PY{c+c1}{\PYZsh{} token counter}
    \PY{n}{counter} \PY{o}{=} \PY{l+m+mi}{0}
    
    \PY{c+c1}{\PYZsh{} output tokens. we insert a \PYZsq{}: \PYZsq{} for formatting}
    \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{n}{tokenize}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{vocab\PYZus{}file}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{vocab\PYZus{}dir}\PY{p}{)}\PY{p}{]}
    
    \PY{c+c1}{\PYZsh{} reset the model state when starting a new dialogue}
    \PY{n}{ReformerLM}\PY{o}{.}\PY{n}{state} \PY{o}{=} \PY{n}{model\PYZus{}state}
    
    \PY{c+c1}{\PYZsh{} calls the output generator implemented earlier}
    \PY{n}{output} \PY{o}{=} \PY{n}{ReformerLM\PYZus{}output\PYZus{}gen}\PY{p}{(}\PY{n}{ReformerLM}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{n}{temperature}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} print the starting sentence}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{start\PYZus{}sentence}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{delimiter\PYZus{}2}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} loop below yields the next tokens until max\PYZus{}len is reached. the if\PYZhy{}elif is just for prettifying the output.}
    \PY{k}{for} \PY{n}{o} \PY{o+ow}{in} \PY{n}{output}\PY{p}{:}
        
        \PY{n}{result}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{o}\PY{p}{)}
        
        \PY{n}{sentence} \PY{o}{=} \PY{n}{detokenize}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{n}{result}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{)}
        
        \PY{k}{if} \PY{n}{sentence}\PY{o}{.}\PY{n}{endswith}\PY{p}{(}\PY{n}{delimiter\PYZus{}1}\PY{p}{)}\PY{p}{:}
            \PY{n}{sentence} \PY{o}{=} \PY{n}{sentence}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{delimiter\PYZus{}1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{delimiter\PYZus{}2}\PY{l+s+si}{\PYZcb{}}\PY{l+s+si}{\PYZob{}}\PY{n}{sentence}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{result}\PY{o}{.}\PY{n}{clear}\PY{p}{(}\PY{p}{)}
        
        \PY{k}{elif} \PY{n}{sentence}\PY{o}{.}\PY{n}{endswith}\PY{p}{(}\PY{n}{delimiter\PYZus{}2}\PY{p}{)}\PY{p}{:}
            \PY{n}{sentence} \PY{o}{=} \PY{n}{sentence}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{delimiter\PYZus{}2}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{delimiter\PYZus{}1}\PY{l+s+si}{\PYZcb{}}\PY{l+s+si}{\PYZob{}}\PY{n}{sentence}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{result}\PY{o}{.}\PY{n}{clear}\PY{p}{(}\PY{p}{)}

        \PY{n}{counter} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{k}{if} \PY{n}{counter} \PY{o}{\PYZgt{}} \PY{n}{max\PYZus{}len}\PY{p}{:}
            \PY{k}{break}    
\end{Verbatim}
\end{tcolorbox}

    We can now feed in different starting sentences and see how the model
generates the dialogue. You can even input your own starting sentence.
Just remember to ask a question that covers the topics in the Multiwoz
dataset so you can generate a meaningful conversation.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{50}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sample\PYZus{}sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 1: Are there theatres in town? Person 2: }\PY{l+s+s1}{\PYZsq{}}
\PY{n}{generate\PYZus{}dialogue}\PY{p}{(}\PY{n}{ReformerLM}\PY{o}{=}\PY{n}{model}\PY{p}{,} \PY{n}{model\PYZus{}state}\PY{o}{=}\PY{n}{STARTING\PYZus{}STATE}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{o}{=}\PY{n}{sample\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{max\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Person 1: Are there theatres in town?
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        KeyboardInterrupt                         Traceback (most recent call last)

        <ipython-input-50-8263c8200064> in <module>
          1 sample\_sentence = ' Person 1: Are there theatres in town? Person 2: '
    ----> 2 generate\_dialogue(ReformerLM=model, model\_state=STARTING\_STATE, start\_sentence=sample\_sentence, vocab\_file=VOCAB\_FILE, vocab\_dir=VOCAB\_DIR, max\_len=120, temperature=0.2)
    

        <ipython-input-49-f0a071c77c42> in generate\_dialogue(ReformerLM, model\_state, start\_sentence, vocab\_file, vocab\_dir, max\_len, temperature)
         39 
         40     \# loop below yields the next tokens until max\_len is reached. the if-elif is just for prettifying the output.
    ---> 41     for o in output:
         42 
         43         result.append(o)


        /opt/conda/lib/python3.7/site-packages/trax/supervised/decoding.py in autoregressive\_sample\_stream(model, inputs, batch\_size, temperature, start\_id, accelerate)
         54     if inputs is not None and model.n\_in > 1:
         55       model\_input = (inputs, cur\_symbol)
    ---> 56     logits = fast\_model(model\_input)
         57     if inputs is not None and model.n\_in > 1:
         58       logits = logits[0]  \# Pick first element from model output (a pair here)


        /opt/conda/lib/python3.7/site-packages/trax/layers/base.py in \_\_call\_\_(self, x, weights, state, rng)
        171       self.state = state  \# Needed if the model wasn't fully initialized.
        172     state = self.state
    --> 173     outputs, new\_state = self.pure\_fn(x, weights, state, rng)
        174     self.state = new\_state
        175     self.weights = weights


        /opt/conda/lib/python3.7/site-packages/trax/layers/acceleration.py in pure\_fn(self, x, weights, state, rng, use\_cache)
         75       remainder = x.shape[0] \% self.\_n\_devices
         76     if remainder == 0:  \# If yes, run the accelerated sublayer.pure\_fn.
    ---> 77       return self.\_jit\_pure\_fn(x, weights, state, rng)
         78     \# If not, pad first.
         79     def pad(z):


        /opt/conda/lib/python3.7/site-packages/jax/api.py in f\_jitted(*args, **kwargs)
        168     flat\_fun, out\_tree = flatten\_fun(f, in\_tree)
        169     out = xla.xla\_call(flat\_fun, *args\_flat, device=device, backend=backend,
    --> 170                        name=flat\_fun.\_\_name\_\_, donated\_invars=donated\_invars)
        171     return tree\_unflatten(out\_tree(), out)
        172 


        /opt/conda/lib/python3.7/site-packages/jax/core.py in call\_bind(primitive, fun, *args, **params)
       1096   if top\_trace is None:
       1097     with new\_sublevel():
    -> 1098       outs = primitive.impl(fun, *args, **params)
       1099   else:
       1100     tracers = map(top\_trace.full\_raise, args)


        /opt/conda/lib/python3.7/site-packages/jax/interpreters/xla.py in \_xla\_call\_impl(fun, device, backend, name, donated\_invars, *args)
        536 def \_xla\_call\_impl(fun: lu.WrappedFun, *args, device, backend, name, donated\_invars):
        537   compiled\_fun = \_xla\_callable(fun, device, backend, name, donated\_invars,
    --> 538                                *unsafe\_map(arg\_spec, args))
        539   try:
        540     return compiled\_fun(*args)


        /opt/conda/lib/python3.7/site-packages/jax/linear\_util.py in memoized\_fun(fun, *args)
        219       fun.populate\_stores(stores)
        220     else:
    --> 221       ans = call(fun, *args)
        222       cache[key] = (ans, fun.stores)
        223     return ans


        /opt/conda/lib/python3.7/site-packages/jax/interpreters/xla.py in \_xla\_callable(fun, device, backend, name, donated\_invars, *arg\_specs)
        663       device\_assignment=(device.id,) if device else None)
        664   options.parameter\_is\_tupled\_arguments = tuple\_args
    --> 665   compiled = backend.compile(built, compile\_options=options)
        666   if nreps == 1:
        667     return partial(\_execute\_compiled, compiled, result\_handlers)


        KeyboardInterrupt: 

    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sample\PYZus{}sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 1: Is there a hospital nearby? Person 2: }\PY{l+s+s1}{\PYZsq{}}
\PY{n}{generate\PYZus{}dialogue}\PY{p}{(}\PY{n}{ReformerLM}\PY{o}{=}\PY{n}{model}\PY{p}{,} \PY{n}{model\PYZus{}state}\PY{o}{=}\PY{n}{STARTING\PYZus{}STATE}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{o}{=}\PY{n}{sample\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{max\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sample\PYZus{}sentence} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ Person 1: Can you book a taxi? Person 2: }\PY{l+s+s1}{\PYZsq{}}
\PY{n}{generate\PYZus{}dialogue}\PY{p}{(}\PY{n}{ReformerLM}\PY{o}{=}\PY{n}{model}\PY{p}{,} \PY{n}{model\PYZus{}state}\PY{o}{=}\PY{n}{STARTING\PYZus{}STATE}\PY{p}{,} \PY{n}{start\PYZus{}sentence}\PY{o}{=}\PY{n}{sample\PYZus{}sentence}\PY{p}{,} \PY{n}{vocab\PYZus{}file}\PY{o}{=}\PY{n}{VOCAB\PYZus{}FILE}\PY{p}{,} \PY{n}{vocab\PYZus{}dir}\PY{o}{=}\PY{n}{VOCAB\PYZus{}DIR}\PY{p}{,} \PY{n}{max\PYZus{}len}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Congratulations! You just wrapped up the final assignment of
this course and the entire specialization!}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
